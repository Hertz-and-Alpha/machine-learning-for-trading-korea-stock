{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long-Short Strategy, Part 5: Generating out-of-sample predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll start designing, implementing, and evaluating a trading strategy for US equities driven by daily return forecasts produced by gradient boosting models.\n",
    "\n",
    "As in the previous examples, we'll lay out a framework and build a specific example that you can adapt to run your own experiments. There are numerous aspects that you can vary, from the asset class and investment universe to more granular aspects like the features, holding period, or trading rules. See, for example, the **Alpha Factor Library** in the [Appendix](../24_alpha_factor_library) for numerous additional features.\n",
    "\n",
    "We'll keep the trading strategy simple and only use a single ML signal; a real-life application will likely use multiple signals from different sources, such as complementary ML models trained on different datasets or with different lookahead or lookback periods. It would also use sophisticated risk management, from simple stop-loss to value-at-risk analysis.\n",
    "\n",
    "**Six notebooks** cover our workflow sequence:\n",
    "\n",
    "1. [preparing_the_model_data](04_preparing_the_model_data.ipyny): we engineer a few simple features from the Quandl Wiki data \n",
    "2. [trading_signals_with_lightgbm_and_catboost](05_trading_signals_with_lightgbm_and_catboost.ipynb): we tune hyperparameters for LightGBM and CatBoost to select a model, using 2015/16 as our validation period. \n",
    "3. [evaluate_trading_signals](06_evaluate_trading_signals): we compare the cross-validation performance using various metrics to select the best model. \n",
    "4. [model_interpretation](07_model_interpretation.ipynb): we take a closer look at the drivers behind the best model's predictions.\n",
    "5. `making_out_of_sample_predictions` (this noteboook): we predict returns for our out-of-sample period 2017.\n",
    "6. [backtesting_with_zipline](09_backtesting_with_zipline.ipynb): evaluate the historical performance of a long-short strategy based on our predictive signals using Zipline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:22.754238Z",
     "start_time": "2021-04-16T03:59:22.751670Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T05:08:44.486465Z",
     "start_time": "2021-04-16T05:08:44.469578Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import lightgbm as lgb\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.584097Z",
     "start_time": "2021-04-16T03:59:23.581416Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from utils import MultipleTimeSeriesCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.598076Z",
     "start_time": "2021-04-16T03:59:23.585119Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.611324Z",
     "start_time": "2021-04-16T03:59:23.598945Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YEAR = 252\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.618708Z",
     "start_time": "2021-04-16T03:59:23.612249Z"
    }
   },
   "outputs": [],
   "source": [
    "scope_params = ['lookahead', 'train_length', 'test_length']\n",
    "daily_ic_metrics = ['daily_ic_mean', 'daily_ic_mean_n', 'daily_ic_median', 'daily_ic_median_n']\n",
    "lgb_train_params = ['learning_rate', 'num_leaves', 'feature_fraction', 'min_data_in_leaf']\n",
    "catboost_train_params = ['max_depth', 'min_child_samples']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LightGBM predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.626636Z",
     "start_time": "2021-04-16T03:59:23.620602Z"
    }
   },
   "outputs": [],
   "source": [
    "base_params = dict(boosting='gbdt',\n",
    "                   objective='regression',\n",
    "                   verbose=-1)\n",
    "\n",
    "categoricals = ['year', 'month', 'sector', 'weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.637221Z",
     "start_time": "2021-04-16T03:59:23.627969Z"
    }
   },
   "outputs": [],
   "source": [
    "lookahead = 1\n",
    "store = Path('data/predictions.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:24.861291Z",
     "start_time": "2021-04-16T03:59:23.638248Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_hdf('data.h5', 'model_data').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:24.872441Z",
     "start_time": "2021-04-16T03:59:24.862170Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = sorted(data.filter(like='_fwd').columns)\n",
    "features = data.columns.difference(labels).tolist()\n",
    "label = f'r{lookahead:02}_fwd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:25.603772Z",
     "start_time": "2021-04-16T03:59:24.873415Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.loc[idx[:, '2010':], features + [label]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:25.670973Z",
     "start_time": "2021-04-16T03:59:25.604625Z"
    }
   },
   "outputs": [],
   "source": [
    "for feature in categoricals:\n",
    "    data[feature] = pd.factorize(data[feature], sort=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:25.743036Z",
     "start_time": "2021-04-16T03:59:25.671795Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_data = lgb.Dataset(data=data[features],\n",
    "                       label=data[label],\n",
    "                       categorical_feature=categoricals,\n",
    "                       free_raw_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:25.860485Z",
     "start_time": "2021-04-16T03:59:25.743923Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_ic = pd.read_hdf('data/model_tuning.h5', 'lgb/ic')\n",
    "lgb_daily_ic = pd.read_hdf('data/model_tuning.h5', 'lgb/daily_ic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:25.863322Z",
     "start_time": "2021-04-16T03:59:25.861312Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_lgb_params(data, t=5, best=0):\n",
    "    param_cols = scope_params[1:] + lgb_train_params + ['boost_rounds']\n",
    "    df = data[data.lookahead==t].sort_values('ic', ascending=False).iloc[best]\n",
    "    return df.loc[param_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:08.945191Z",
     "start_time": "2021-04-16T03:59:25.864181Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Position: 00\n",
      "1 2 3 4 \n",
      "Position: 01\n",
      "1 2 3 4 \n",
      "Position: 02\n",
      "1 2 3 4 \n",
      "Position: 03\n",
      "1 2 3 4 \n",
      "Position: 04\n",
      "1 2 3 4 \n",
      "Position: 05\n",
      "1 2 3 4 \n",
      "Position: 06\n",
      "1 2 3 4 \n",
      "Position: 07\n",
      "1 2 3 4 \n",
      "Position: 08\n",
      "1 2 3 4 \n",
      "Position: 09\n",
      "1 2 3 4                 0           1           2           3           4           5  \\\n",
      "count  252.000000  252.000000  252.000000  252.000000  252.000000  252.000000   \n",
      "mean     0.072090    0.072376    0.071830    0.067271    0.066911    0.067975   \n",
      "std      0.065433    0.065185    0.065711    0.059329    0.060156    0.060200   \n",
      "min     -0.084236   -0.083583   -0.091410   -0.109422   -0.100130   -0.105375   \n",
      "25%      0.024670    0.023728    0.021482    0.030853    0.027979    0.025635   \n",
      "50%      0.071151    0.071740    0.071553    0.067614    0.067121    0.064517   \n",
      "75%      0.114978    0.116825    0.117116    0.109407    0.106528    0.111653   \n",
      "max      0.246004    0.248800    0.247246    0.234732    0.211464    0.202822   \n",
      "\n",
      "                6           7           8           9  \n",
      "count  252.000000  252.000000  252.000000  252.000000  \n",
      "mean     0.071628    0.063087    0.067110    0.066723  \n",
      "std      0.065762    0.059380    0.059795    0.059996  \n",
      "min     -0.092962   -0.165646   -0.082349   -0.104710  \n",
      "25%      0.021035    0.024470    0.024165    0.025598  \n",
      "50%      0.072340    0.064748    0.069208    0.065587  \n",
      "75%      0.115943    0.107666    0.107434    0.109554  \n",
      "max      0.246660    0.208519    0.231740    0.211910  \n"
     ]
    }
   ],
   "source": [
    "for position in range(10):\n",
    "    params = get_lgb_params(lgb_daily_ic,\n",
    "                            t=lookahead,\n",
    "                            best=position)\n",
    "\n",
    "    params = params.to_dict()\n",
    "\n",
    "    for p in ['min_data_in_leaf', 'num_leaves']:\n",
    "        params[p] = int(params[p])\n",
    "    train_length = int(params.pop('train_length'))\n",
    "    test_length = int(params.pop('test_length'))\n",
    "    num_boost_round = int(params.pop('boost_rounds'))\n",
    "    params.update(base_params)\n",
    "\n",
    "    print(f'\\nPosition: {position:02}')\n",
    "\n",
    "    # 1-year out-of-sample period\n",
    "    n_splits = int(YEAR / test_length)\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              test_period_length=test_length,\n",
    "                              lookahead=lookahead,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    predictions = []\n",
    "    start = time()\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X=data), 1):\n",
    "        print(i, end=' ', flush=True)\n",
    "        lgb_train = lgb_data.subset(used_indices=train_idx.tolist(),\n",
    "                                    params=params).construct()\n",
    "\n",
    "        model = lgb.train(params=params,\n",
    "                          train_set=lgb_train,\n",
    "                          num_boost_round=num_boost_round,\n",
    "                          verbose_eval=False)\n",
    "\n",
    "        test_set = data.iloc[test_idx, :]\n",
    "        y_test = test_set.loc[:, label].to_frame('y_test')\n",
    "        y_pred = model.predict(test_set.loc[:, model.feature_name()])\n",
    "        predictions.append(y_test.assign(prediction=y_pred))\n",
    "\n",
    "    if position == 0:\n",
    "        test_predictions = (pd.concat(predictions)\n",
    "                            .rename(columns={'prediction': position}))\n",
    "    else:\n",
    "        test_predictions[position] = pd.concat(predictions).prediction\n",
    "\n",
    "by_day = test_predictions.groupby(level='date')\n",
    "for position in range(10):\n",
    "    if position == 0:\n",
    "        ic_by_day = by_day.apply(lambda x: spearmanr(\n",
    "            x.y_test, x[position])[0]).to_frame()\n",
    "    else:\n",
    "        ic_by_day[position] = by_day.apply(\n",
    "            lambda x: spearmanr(x.y_test, x[position])[0])\n",
    "print(ic_by_day.describe())\n",
    "test_predictions.to_hdf(store, f'lgb/test/{lookahead:02}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CatBoost predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:47:49.952398Z",
     "start_time": "2021-04-16T04:47:49.946516Z"
    }
   },
   "outputs": [],
   "source": [
    "lookaheads = [1, 5, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:47:50.159085Z",
     "start_time": "2021-04-16T04:47:50.155503Z"
    }
   },
   "outputs": [],
   "source": [
    "label_dict = dict(zip(lookaheads, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:21.239471Z",
     "start_time": "2021-04-16T04:42:21.237509Z"
    }
   },
   "outputs": [],
   "source": [
    "lookahead = 1\n",
    "store = Path('data/predictions.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:33.046167Z",
     "start_time": "2021-04-16T04:42:30.939809Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_hdf('data.h5', 'model_data').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:33.057677Z",
     "start_time": "2021-04-16T04:42:33.047222Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = sorted(data.filter(like='_fwd').columns)\n",
    "features = data.columns.difference(labels).tolist()\n",
    "label = f'r{lookahead:02}_fwd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:34.147080Z",
     "start_time": "2021-04-16T04:42:33.058841Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.loc[idx[:, '2010':], features + [label]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:34.278518Z",
     "start_time": "2021-04-16T04:42:34.148155Z"
    }
   },
   "outputs": [],
   "source": [
    "for feature in categoricals:\n",
    "    data[feature] = pd.factorize(data[feature], sort=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:49:29.805949Z",
     "start_time": "2021-04-16T04:49:29.799821Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols_idx = [data.columns.get_loc(c) for c in categoricals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:49:31.122802Z",
     "start_time": "2021-04-16T04:49:30.128972Z"
    }
   },
   "outputs": [],
   "source": [
    "catboost_data = Pool(label=data[label],\n",
    "                     data=data.drop(label, axis=1),\n",
    "                     cat_features=cat_cols_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T05:07:56.282852Z",
     "start_time": "2021-04-16T05:07:56.226707Z"
    }
   },
   "outputs": [],
   "source": [
    "catboost_ic = pd.read_hdf('data/model_tuning.h5', 'catboost/ic')\n",
    "catboost_ic_avg = pd.read_hdf('data/model_tuning.h5', 'catboost/daily_ic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T05:07:57.137679Z",
     "start_time": "2021-04-16T05:07:57.135665Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cb_params(data, t=5, best=0):\n",
    "    param_cols = scope_params[1:] + catboost_train_params + ['boost_rounds']\n",
    "    df = data[data.lookahead==t].sort_values('ic', ascending=False).iloc[best]\n",
    "    return df.loc[param_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T05:09:16.726292Z",
     "start_time": "2021-04-16T05:08:48.185974Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Position: 00\n",
      "1 <catboost.core.CatBoostRegressor object at 0x0000019B0004EA00>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x0000019B1054F580>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x0000019B103D12B0>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x0000019B1054F3A0>\n",
      "\n",
      "Position: 01\n",
      "1 <catboost.core.CatBoostRegressor object at 0x0000019B00032A60>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x0000019B1054F970>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x0000019B103D1FD0>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x0000019B103DD130>\n",
      "\n",
      "Position: 02\n",
      "1 <catboost.core.CatBoostRegressor object at 0x0000019B00032DC0>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x0000019B1054F070>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x0000019B103D1670>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x0000019B103DDB50>\n",
      "\n",
      "Position: 03\n",
      "1 <catboost.core.CatBoostRegressor object at 0x0000019B103D1FA0>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x0000019B103DDB80>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x0000019B1054F580>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x0000019B0004E1C0>\n",
      "\n",
      "Position: 04\n",
      "1 <catboost.core.CatBoostRegressor object at 0x0000019B1054FFA0>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x0000019B103DDCD0>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x0000019B0004EFD0>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x0000019B10A52490>\n",
      "\n",
      "Position: 05\n",
      "1 <catboost.core.CatBoostRegressor object at 0x0000019B73699190>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x0000019B103D14C0>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x0000019B1054FD60>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x0000019B103DDBE0>\n",
      "\n",
      "Position: 06\n",
      "1 <catboost.core.CatBoostRegressor object at 0x0000019B1054FC10>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x0000019B103DD7C0>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x0000019B1054F670>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x0000019B103D12E0>\n",
      "\n",
      "Position: 07\n",
      "1 <catboost.core.CatBoostRegressor object at 0x0000019B1054F0D0>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x0000019B103DD9A0>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x0000019B103D1400>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x0000019B103DDF10>\n",
      "\n",
      "Position: 08\n",
      "1 <catboost.core.CatBoostRegressor object at 0x0000019B103D1490>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x0000019B0004E3A0>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x0000019B103D1E80>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x0000019B103DD610>\n",
      "\n",
      "Position: 09\n",
      "1 <catboost.core.CatBoostRegressor object at 0x0000019B103D1FA0>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x0000019B0004E4C0>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x0000019B103D1E80>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x0000019B103DD820>\n",
      "                0           1           2           3           4           5  \\\n",
      "count  207.000000  252.000000  207.000000  207.000000  207.000000  207.000000   \n",
      "mean    -0.002584   -0.007493   -0.002584   -0.002609   -0.002584   -0.002609   \n",
      "std      0.056677    0.075105    0.056677    0.056692    0.056677    0.056692   \n",
      "min     -0.195981   -0.196992   -0.195981   -0.195981   -0.195981   -0.195981   \n",
      "25%     -0.039169   -0.059695   -0.039169   -0.039169   -0.039169   -0.039169   \n",
      "50%      0.002745   -0.004297    0.002745    0.002745    0.002745    0.002745   \n",
      "75%      0.034297    0.042966    0.034297    0.034297    0.034297    0.034297   \n",
      "max      0.139419    0.164991    0.139419    0.139419    0.139419    0.139419   \n",
      "\n",
      "                6           7           8           9  \n",
      "count  252.000000  252.000000  252.000000  252.000000  \n",
      "mean    -0.007493   -0.007493   -0.007493   -0.007493  \n",
      "std      0.075105    0.075105    0.075105    0.075105  \n",
      "min     -0.196992   -0.196992   -0.196992   -0.196992  \n",
      "25%     -0.059695   -0.059695   -0.059695   -0.059695  \n",
      "50%     -0.004297   -0.004297   -0.004297   -0.004297  \n",
      "75%      0.042966    0.042966    0.042966    0.042966  \n",
      "max      0.164991    0.164991    0.164991    0.164991  \n"
     ]
    }
   ],
   "source": [
    "for position in range(10):\n",
    "    params = get_cb_params(catboost_ic_avg,\n",
    "                    t=lookahead,\n",
    "                    best=position)\n",
    "    \n",
    "    params = params.to_dict()\n",
    "    \n",
    "    for p in ['max_depth', 'min_child_samples']:\n",
    "        params[p] = int(params[p])\n",
    "    train_length = int(params.pop('train_length'))\n",
    "    test_length = int(params.pop('test_length'))\n",
    "    num_boost_round = int(params.pop('boost_rounds'))\n",
    "    params['task_type'] = 'GPU'\n",
    "\n",
    "    print(f'\\nPosition: {position:02}')\n",
    "    \n",
    "    # 1-year out-of-sample period\n",
    "    n_splits = int(YEAR / test_length)\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              test_period_length=test_length,\n",
    "                              lookahead=lookahead,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    predictions = []\n",
    "    start = time()\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X=data), 1):\n",
    "        print(i, end=' ', flush=True)\n",
    "        train_set = catboost_data.slice(train_idx.tolist())\n",
    "\n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(X=train_set,\n",
    "                  verbose_eval=False)\n",
    "\n",
    "        test_set = data.iloc[test_idx, :]\n",
    "        y_test = test_set.loc[:, label].to_frame('y_test')\n",
    "        print(model)\n",
    "#         print(model.feature_names_)\n",
    "        \n",
    "        y_pred = model.predict(test_set.loc[:, model.feature_names_])\n",
    "        predictions.append(y_test.assign(prediction=y_pred))\n",
    "\n",
    "    if position == 0:\n",
    "        test_predictions = (pd.concat(predictions)\n",
    "                            .rename(columns={'prediction': position}))\n",
    "    else:\n",
    "        test_predictions[position] = pd.concat(predictions).prediction\n",
    "\n",
    "by_day = test_predictions.groupby(level='date')\n",
    "for position in range(10):\n",
    "    if position == 0:\n",
    "        ic_by_day = by_day.apply(lambda x: spearmanr(x.y_test, x[position])[0]).to_frame()\n",
    "    else:\n",
    "        ic_by_day[position] = by_day.apply(lambda x: spearmanr(x.y_test, x[position])[0])\n",
    "print(ic_by_day.describe())\n",
    "test_predictions.to_hdf(store, f'catboost/test/{lookahead:02}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml4t]",
   "language": "python",
   "name": "conda-env-ml4t-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "301.861px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

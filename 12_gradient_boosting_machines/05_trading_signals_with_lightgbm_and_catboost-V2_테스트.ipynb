{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long-Short Strategy, Part 2: Trading signals with LightGBM and CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll start designing, implementing, and evaluating a trading strategy for US equities driven by daily return forecasts produced by gradient boosting models.\n",
    "\n",
    "As in the previous examples, we'll lay out a framework and build a specific example that you can adapt to run your own experiments. There are numerous aspects that you can vary, from the asset class and investment universe to more granular aspects like the features, holding period, or trading rules. See, for example, the **Alpha Factor Library** in the [Appendix](../24_alpha_factor_library) for numerous additional features.\n",
    "\n",
    "We'll keep the trading strategy simple and only use a single ML signal; a real-life application will likely use multiple signals from different sources, such as complementary ML models trained on different datasets or with different lookahead or lookback periods. It would also use sophisticated risk management, from simple stop-loss to value-at-risk analysis.\n",
    "\n",
    "**Six notebooks** cover our workflow sequence:\n",
    "\n",
    "1. [preparing_the_model_data](04_preparing_the_model_data.ipyny): we engineer a few simple features from the Quandl Wiki data \n",
    "2. `trading_signals_with_lightgbm_and_catboost`  (this noteboook): we tune hyperparameters for LightGBM and CatBoost to select a model, using 2015/16 as our validation period. \n",
    "3. [evaluate_trading_signals](06_evaluate_trading_signals.ipynb): we compare the cross-validation performance using various metrics to select the best model. \n",
    "4. [model_interpretation](07_model_interpretation.ipynb): we take a closer look at the drivers behind the best model's predictions.\n",
    "5. [making_out_of_sample_predictions](08_making_out_of_sample_predictions.ipynb): we generate predictions for our out-of-sample test period 2017.\n",
    "6. [backtesting_with_zipline](09_backtesting_with_zipline.ipynb): evaluate the historical performance of a long-short strategy based on our predictive signals using Zipline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll subset the dataset created in the preceding notebook through the end of 2016 to cross-validate several model configurations for various lookback and lookahead windows, as well as different roll-forward periods and hyperparameters. \n",
    "\n",
    "Our approach to model selection will be similar to the one we used in the previous chapter and uses the custom `MultipleTimeSeriesCV` introduced in [Chapter 7, Linear Models – From Risk Factors to Return Forecasts](../07_linear_models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:53.361121Z",
     "start_time": "2020-06-21T03:15:53.359422Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:54.473652Z",
     "start_time": "2020-06-21T03:15:53.619170Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, os\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from alphalens.tears import (create_summary_tear_sheet,\n",
    "                             create_full_tear_sheet)\n",
    "\n",
    "from alphalens.utils import get_clean_factor_and_forward_returns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:54.477216Z",
     "start_time": "2020-06-21T03:15:54.474618Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from utils import MultipleTimeSeriesCV, format_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:54.489618Z",
     "start_time": "2020-06-21T03:15:54.478409Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:54.626839Z",
     "start_time": "2020-06-21T03:15:54.624975Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YEAR = 252\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the train and validation sets, and identify labels and features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.610627Z",
     "start_time": "2020-06-21T03:15:56.699840Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1110557 entries, ('000020', Timestamp('2010-04-05 00:00:00')) to ('128820', Timestamp('2017-12-28 00:00:00'))\n",
      "Data columns (total 34 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   dollar_vol       1110557 non-null  float64\n",
      " 1   dollar_vol_rank  1110557 non-null  float64\n",
      " 2   rsi              1110557 non-null  float64\n",
      " 3   bb_high          1110557 non-null  float64\n",
      " 4   bb_low           1110557 non-null  float64\n",
      " 5   NATR             1110557 non-null  float64\n",
      " 6   ATR              1110557 non-null  float64\n",
      " 7   PPO              1110557 non-null  float64\n",
      " 8   MACD             1110557 non-null  float64\n",
      " 9   sector           1110557 non-null  int32  \n",
      " 10  r01              1110557 non-null  float64\n",
      " 11  r05              1110557 non-null  float64\n",
      " 12  r10              1110557 non-null  float64\n",
      " 13  r21              1110557 non-null  float64\n",
      " 14  r42              1110557 non-null  float64\n",
      " 15  r63              1110557 non-null  float64\n",
      " 16  r01dec           1110557 non-null  int64  \n",
      " 17  r05dec           1110557 non-null  int64  \n",
      " 18  r10dec           1110557 non-null  int64  \n",
      " 19  r21dec           1110557 non-null  int64  \n",
      " 20  r42dec           1110557 non-null  int64  \n",
      " 21  r63dec           1110557 non-null  int64  \n",
      " 22  r01q_sector      1036280 non-null  float64\n",
      " 23  r05q_sector      1036687 non-null  float64\n",
      " 24  r10q_sector      1036709 non-null  float64\n",
      " 25  r21q_sector      1036729 non-null  float64\n",
      " 26  r42q_sector      1036737 non-null  float64\n",
      " 27  r63q_sector      1036739 non-null  float64\n",
      " 28  r01_fwd          1109973 non-null  float64\n",
      " 29  r05_fwd          1107637 non-null  float64\n",
      " 30  r21_fwd          1098293 non-null  float64\n",
      " 31  year             1110557 non-null  int64  \n",
      " 32  month            1110557 non-null  int64  \n",
      " 33  weekday          1110557 non-null  int64  \n",
      "dtypes: float64(24), int32(1), int64(9)\n",
      "memory usage: 288.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data = (pd.read_hdf('data.h5', 'model_data')\n",
    "            .sort_index()\n",
    "            .loc[idx[:, :'2017'], :]) # train & validation period\n",
    "data.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.627071Z",
     "start_time": "2020-06-21T03:15:58.611792Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = sorted(data.filter(like='_fwd').columns)\n",
    "features = data.columns.difference(labels).tolist() # features are columns not containing '_fwd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>dollar_vol</th>\n",
       "      <th>dollar_vol_rank</th>\n",
       "      <th>rsi</th>\n",
       "      <th>bb_high</th>\n",
       "      <th>bb_low</th>\n",
       "      <th>NATR</th>\n",
       "      <th>ATR</th>\n",
       "      <th>PPO</th>\n",
       "      <th>MACD</th>\n",
       "      <th>sector</th>\n",
       "      <th>...</th>\n",
       "      <th>r10q_sector</th>\n",
       "      <th>r21q_sector</th>\n",
       "      <th>r42q_sector</th>\n",
       "      <th>r63q_sector</th>\n",
       "      <th>r01_fwd</th>\n",
       "      <th>r05_fwd</th>\n",
       "      <th>r21_fwd</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">000020</th>\n",
       "      <th>2010-04-05</th>\n",
       "      <td>1014.005040</td>\n",
       "      <td>243.0</td>\n",
       "      <td>32.814698</td>\n",
       "      <td>0.091034</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>2.173222</td>\n",
       "      <td>-0.854541</td>\n",
       "      <td>-1.252542</td>\n",
       "      <td>-0.557743</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023973</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.011986</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-06</th>\n",
       "      <td>501.243600</td>\n",
       "      <td>248.0</td>\n",
       "      <td>42.846934</td>\n",
       "      <td>0.071166</td>\n",
       "      <td>0.026926</td>\n",
       "      <td>2.161861</td>\n",
       "      <td>-0.832321</td>\n",
       "      <td>-1.565939</td>\n",
       "      <td>-0.549990</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.031773</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-07</th>\n",
       "      <td>546.932100</td>\n",
       "      <td>256.0</td>\n",
       "      <td>47.100287</td>\n",
       "      <td>0.059957</td>\n",
       "      <td>0.039134</td>\n",
       "      <td>2.137699</td>\n",
       "      <td>-0.831836</td>\n",
       "      <td>-1.734365</td>\n",
       "      <td>-0.501830</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>-0.009917</td>\n",
       "      <td>-0.077686</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-08</th>\n",
       "      <td>478.094720</td>\n",
       "      <td>258.0</td>\n",
       "      <td>48.856942</td>\n",
       "      <td>0.049861</td>\n",
       "      <td>0.042282</td>\n",
       "      <td>2.057448</td>\n",
       "      <td>-0.871685</td>\n",
       "      <td>-1.786313</td>\n",
       "      <td>-0.443558</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.014803</td>\n",
       "      <td>-0.004934</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-09</th>\n",
       "      <td>440.564500</td>\n",
       "      <td>268.0</td>\n",
       "      <td>44.123185</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.027901</td>\n",
       "      <td>2.046515</td>\n",
       "      <td>-0.895254</td>\n",
       "      <td>-1.842072</td>\n",
       "      <td>-0.441020</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>-0.053422</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">128820</th>\n",
       "      <th>2017-12-21</th>\n",
       "      <td>290.727720</td>\n",
       "      <td>400.0</td>\n",
       "      <td>54.064530</td>\n",
       "      <td>0.048743</td>\n",
       "      <td>0.045690</td>\n",
       "      <td>4.301318</td>\n",
       "      <td>-0.793255</td>\n",
       "      <td>-1.675968</td>\n",
       "      <td>0.369005</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-22</th>\n",
       "      <td>172.874405</td>\n",
       "      <td>401.0</td>\n",
       "      <td>53.710598</td>\n",
       "      <td>0.048028</td>\n",
       "      <td>0.044759</td>\n",
       "      <td>4.154569</td>\n",
       "      <td>-0.796892</td>\n",
       "      <td>-1.614101</td>\n",
       "      <td>0.369026</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.023066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-26</th>\n",
       "      <td>281.401200</td>\n",
       "      <td>409.0</td>\n",
       "      <td>47.962284</td>\n",
       "      <td>0.059577</td>\n",
       "      <td>0.020469</td>\n",
       "      <td>4.216758</td>\n",
       "      <td>-0.797728</td>\n",
       "      <td>-1.599051</td>\n",
       "      <td>0.363626</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-27</th>\n",
       "      <td>220.453415</td>\n",
       "      <td>411.0</td>\n",
       "      <td>52.177251</td>\n",
       "      <td>0.029847</td>\n",
       "      <td>0.029177</td>\n",
       "      <td>4.021522</td>\n",
       "      <td>-0.800583</td>\n",
       "      <td>-1.509005</td>\n",
       "      <td>0.363177</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>381.716725</td>\n",
       "      <td>415.0</td>\n",
       "      <td>61.060746</td>\n",
       "      <td>-0.008966</td>\n",
       "      <td>0.073277</td>\n",
       "      <td>3.969183</td>\n",
       "      <td>-0.797460</td>\n",
       "      <td>-1.204955</td>\n",
       "      <td>0.373009</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1110557 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    dollar_vol  dollar_vol_rank        rsi   bb_high  \\\n",
       "symbol date                                                            \n",
       "000020 2010-04-05  1014.005040            243.0  32.814698  0.091034   \n",
       "       2010-04-06   501.243600            248.0  42.846934  0.071166   \n",
       "       2010-04-07   546.932100            256.0  47.100287  0.059957   \n",
       "       2010-04-08   478.094720            258.0  48.856942  0.049861   \n",
       "       2010-04-09   440.564500            268.0  44.123185  0.057312   \n",
       "...                        ...              ...        ...       ...   \n",
       "128820 2017-12-21   290.727720            400.0  54.064530  0.048743   \n",
       "       2017-12-22   172.874405            401.0  53.710598  0.048028   \n",
       "       2017-12-26   281.401200            409.0  47.962284  0.059577   \n",
       "       2017-12-27   220.453415            411.0  52.177251  0.029847   \n",
       "       2017-12-28   381.716725            415.0  61.060746 -0.008966   \n",
       "\n",
       "                     bb_low      NATR       ATR       PPO      MACD  sector  \\\n",
       "symbol date                                                                   \n",
       "000020 2010-04-05  0.001407  2.173222 -0.854541 -1.252542 -0.557743      30   \n",
       "       2010-04-06  0.026926  2.161861 -0.832321 -1.565939 -0.549990      30   \n",
       "       2010-04-07  0.039134  2.137699 -0.831836 -1.734365 -0.501830      30   \n",
       "       2010-04-08  0.042282  2.057448 -0.871685 -1.786313 -0.443558      30   \n",
       "       2010-04-09  0.027901  2.046515 -0.895254 -1.842072 -0.441020      30   \n",
       "...                     ...       ...       ...       ...       ...     ...   \n",
       "128820 2017-12-21  0.045690  4.301318 -0.793255 -1.675968  0.369005      87   \n",
       "       2017-12-22  0.044759  4.154569 -0.796892 -1.614101  0.369026      87   \n",
       "       2017-12-26  0.020469  4.216758 -0.797728 -1.599051  0.363626      87   \n",
       "       2017-12-27  0.029177  4.021522 -0.800583 -1.509005  0.363177      87   \n",
       "       2017-12-28  0.073277  3.969183 -0.797460 -1.204955  0.373009      87   \n",
       "\n",
       "                   ...  r10q_sector  r21q_sector  r42q_sector  r63q_sector  \\\n",
       "symbol date        ...                                                       \n",
       "000020 2010-04-05  ...          1.0          2.0          2.0          0.0   \n",
       "       2010-04-06  ...          2.0          2.0          3.0          0.0   \n",
       "       2010-04-07  ...          3.0          2.0          2.0          0.0   \n",
       "       2010-04-08  ...          3.0          2.0          3.0          0.0   \n",
       "       2010-04-09  ...          3.0          1.0          2.0          0.0   \n",
       "...                ...          ...          ...          ...          ...   \n",
       "128820 2017-12-21  ...          NaN          NaN          NaN          NaN   \n",
       "       2017-12-22  ...          NaN          NaN          NaN          NaN   \n",
       "       2017-12-26  ...          NaN          NaN          NaN          NaN   \n",
       "       2017-12-27  ...          NaN          NaN          NaN          NaN   \n",
       "       2017-12-28  ...          NaN          NaN          NaN          NaN   \n",
       "\n",
       "                    r01_fwd   r05_fwd   r21_fwd  year  month  weekday  \n",
       "symbol date                                                            \n",
       "000020 2010-04-05  0.023973  0.027397  0.011986  2010      4        0  \n",
       "       2010-04-06  0.011706  0.000000 -0.031773  2010      4        1  \n",
       "       2010-04-07  0.004959 -0.009917 -0.077686  2010      4        2  \n",
       "       2010-04-08 -0.014803 -0.004934 -0.062500  2010      4        3  \n",
       "       2010-04-09  0.001669  0.003339 -0.053422  2010      4        4  \n",
       "...                     ...       ...       ...   ...    ...      ...  \n",
       "128820 2017-12-21 -0.001355       NaN       NaN  2017     12        3  \n",
       "       2017-12-22 -0.023066       NaN       NaN  2017     12        4  \n",
       "       2017-12-26  0.018056       NaN       NaN  2017     12        1  \n",
       "       2017-12-27  0.046385       NaN       NaN  2017     12        2  \n",
       "       2017-12-28       NaN       NaN       NaN  2017     12        3  \n",
       "\n",
       "[1110557 rows x 34 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection: Lookback, lookahead and roll-forward periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.713463Z",
     "start_time": "2020-06-21T03:15:58.628189Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tickers = data.index.get_level_values('symbol').unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to predict 1, 5 or 21-day returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.716838Z",
     "start_time": "2020-06-21T03:15:58.714860Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lookaheads = [1, 5, 21]\n",
    "# lookaheads = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.726739Z",
     "start_time": "2020-06-21T03:15:58.718248Z"
    }
   },
   "outputs": [],
   "source": [
    "categoricals = ['year', 'month', 'sector', 'weekday']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select 4.5 and one years as the length of our training periods; test periods are one and three months long. Since we are using two years (2015/16) for validation, a one-month test period implies 24 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.735386Z",
     "start_time": "2020-06-21T03:15:58.728023Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_lengths = [int(4.5 * 252), 252]\n",
    "test_lengths = [63, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.743174Z",
     "start_time": "2020-06-21T03:15:58.737182Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_params = list(product(lookaheads, train_lengths, test_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.751241Z",
     "start_time": "2020-06-21T03:15:58.744605Z"
    }
   },
   "outputs": [],
   "source": [
    "results_path = Path('results', 'kr_stocks')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We always want to know how much our (gradient boosting) is improving over a simpler baseline (if at all..)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:16:05.129548Z",
     "start_time": "2020-06-21T03:16:05.127693Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.679350Z",
     "start_time": "2020-06-21T03:16:05.270137Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    715     716     717 ... 1035557 1035558 1035559]\n",
      "[    652     653     654 ... 1035494 1035495 1035496]\n",
      "[    589     590     591 ... 1035431 1035432 1035433]\n",
      "[    526     527     528 ... 1035368 1035369 1035370]\n",
      "[    463     464     465 ... 1035305 1035306 1035307]\n",
      "[    400     401     402 ... 1035242 1035243 1035244]\n",
      "[    337     338     339 ... 1035179 1035180 1035181]\n",
      "[    274     275     276 ... 1035116 1035117 1035118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▉                                                                            | 1/12 [00:33<06:03, 33.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    757     758     759 ... 1035599 1035600 1035601]\n",
      "[    736     737     738 ... 1035578 1035579 1035580]\n",
      "[    715     716     717 ... 1035557 1035558 1035559]\n",
      "[    694     695     696 ... 1035536 1035537 1035538]\n",
      "[    673     674     675 ... 1035515 1035516 1035517]\n",
      "[    652     653     654 ... 1035494 1035495 1035496]\n",
      "[    631     632     633 ... 1035473 1035474 1035475]\n",
      "[    610     611     612 ... 1035452 1035453 1035454]\n",
      "[    589     590     591 ... 1035431 1035432 1035433]\n",
      "[    568     569     570 ... 1035410 1035411 1035412]\n",
      "[    547     548     549 ... 1035389 1035390 1035391]\n",
      "[    526     527     528 ... 1035368 1035369 1035370]\n",
      "[    505     506     507 ... 1035347 1035348 1035349]\n",
      "[    484     485     486 ... 1035326 1035327 1035328]\n",
      "[    463     464     465 ... 1035305 1035306 1035307]\n",
      "[    442     443     444 ... 1035284 1035285 1035286]\n",
      "[    421     422     423 ... 1035263 1035264 1035265]\n",
      "[    400     401     402 ... 1035242 1035243 1035244]\n",
      "[    379     380     381 ... 1035221 1035222 1035223]\n",
      "[    358     359     360 ... 1035200 1035201 1035202]\n",
      "[    337     338     339 ... 1035179 1035180 1035181]\n",
      "[    316     317     318 ... 1035158 1035159 1035160]\n",
      "[    295     296     297 ... 1035137 1035138 1035139]\n",
      "[    274     275     276 ... 1035116 1035117 1035118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▊                                                                     | 2/12 [02:02<11:01, 66.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1597    1598    1599 ... 1035557 1035558 1035559]\n",
      "[   1534    1535    1536 ... 1035494 1035495 1035496]\n",
      "[   1471    1472    1473 ... 1035431 1035432 1035433]\n",
      "[   1408    1409    1410 ... 1035368 1035369 1035370]\n",
      "[   1345    1346    1347 ... 1035305 1035306 1035307]\n",
      "[   1282    1283    1284 ... 1035242 1035243 1035244]\n",
      "[   1219    1220    1221 ... 1035179 1035180 1035181]\n",
      "[   1156    1157    1158 ... 1035116 1035117 1035118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 3/12 [02:10<05:55, 39.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1639    1640    1641 ... 1035599 1035600 1035601]\n",
      "[   1618    1619    1620 ... 1035578 1035579 1035580]\n",
      "[   1597    1598    1599 ... 1035557 1035558 1035559]\n",
      "[   1576    1577    1578 ... 1035536 1035537 1035538]\n",
      "[   1555    1556    1557 ... 1035515 1035516 1035517]\n",
      "[   1534    1535    1536 ... 1035494 1035495 1035496]\n",
      "[   1513    1514    1515 ... 1035473 1035474 1035475]\n",
      "[   1492    1493    1494 ... 1035452 1035453 1035454]\n",
      "[   1471    1472    1473 ... 1035431 1035432 1035433]\n",
      "[   1450    1451    1452 ... 1035410 1035411 1035412]\n",
      "[   1429    1430    1431 ... 1035389 1035390 1035391]\n",
      "[   1408    1409    1410 ... 1035368 1035369 1035370]\n",
      "[   1387    1388    1389 ... 1035347 1035348 1035349]\n",
      "[   1366    1367    1368 ... 1035326 1035327 1035328]\n",
      "[   1345    1346    1347 ... 1035305 1035306 1035307]\n",
      "[   1324    1325    1326 ... 1035284 1035285 1035286]\n",
      "[   1303    1304    1305 ... 1035263 1035264 1035265]\n",
      "[   1282    1283    1284 ... 1035242 1035243 1035244]\n",
      "[   1261    1262    1263 ... 1035221 1035222 1035223]\n",
      "[   1240    1241    1242 ... 1035200 1035201 1035202]\n",
      "[   1219    1220    1221 ... 1035179 1035180 1035181]\n",
      "[   1198    1199    1200 ... 1035158 1035159 1035160]\n",
      "[   1177    1178    1179 ... 1035137 1035138 1035139]\n",
      "[   1156    1157    1158 ... 1035116 1035117 1035118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████████▋                                                       | 4/12 [02:28<04:09, 31.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    703     704     705 ... 1033377 1033378 1033379]\n",
      "[    640     641     642 ... 1033314 1033315 1033316]\n",
      "[    577     578     579 ... 1033251 1033252 1033253]\n",
      "[    514     515     516 ... 1033188 1033189 1033190]\n",
      "[    451     452     453 ... 1033125 1033126 1033127]\n",
      "[    388     389     390 ... 1033062 1033063 1033064]\n",
      "[    325     326     327 ... 1032999 1033000 1033001]\n",
      "[    262     263     264 ... 1032936 1032937 1032938]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████▌                                                | 5/12 [03:00<03:41, 31.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    745     746     747 ... 1033419 1033420 1033421]\n",
      "[    724     725     726 ... 1033398 1033399 1033400]\n",
      "[    703     704     705 ... 1033377 1033378 1033379]\n",
      "[    682     683     684 ... 1033356 1033357 1033358]\n",
      "[    661     662     663 ... 1033335 1033336 1033337]\n",
      "[    640     641     642 ... 1033314 1033315 1033316]\n",
      "[    619     620     621 ... 1033293 1033294 1033295]\n",
      "[    598     599     600 ... 1033272 1033273 1033274]\n",
      "[    577     578     579 ... 1033251 1033252 1033253]\n",
      "[    556     557     558 ... 1033230 1033231 1033232]\n",
      "[    535     536     537 ... 1033209 1033210 1033211]\n",
      "[    514     515     516 ... 1033188 1033189 1033190]\n",
      "[    493     494     495 ... 1033167 1033168 1033169]\n",
      "[    472     473     474 ... 1033146 1033147 1033148]\n",
      "[    451     452     453 ... 1033125 1033126 1033127]\n",
      "[    430     431     432 ... 1033104 1033105 1033106]\n",
      "[    409     410     411 ... 1033083 1033084 1033085]\n",
      "[    388     389     390 ... 1033062 1033063 1033064]\n",
      "[    367     368     369 ... 1033041 1033042 1033043]\n",
      "[    346     347     348 ... 1033020 1033021 1033022]\n",
      "[    325     326     327 ... 1032999 1033000 1033001]\n",
      "[    304     305     306 ... 1032978 1032979 1032980]\n",
      "[    283     284     285 ... 1032957 1032958 1032959]\n",
      "[    262     263     264 ... 1032936 1032937 1032938]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 6/12 [04:31<05:10, 51.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1585    1586    1587 ... 1033377 1033378 1033379]\n",
      "[   1522    1523    1524 ... 1033314 1033315 1033316]\n",
      "[   1459    1460    1461 ... 1033251 1033252 1033253]\n",
      "[   1396    1397    1398 ... 1033188 1033189 1033190]\n",
      "[   1333    1334    1335 ... 1033125 1033126 1033127]\n",
      "[   1270    1271    1272 ... 1033062 1033063 1033064]\n",
      "[   1207    1208    1209 ... 1032999 1033000 1033001]\n",
      "[   1144    1145    1146 ... 1032936 1032937 1032938]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|████████████████████████████████████████████████▍                                  | 7/12 [04:39<03:06, 37.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1627    1628    1629 ... 1033419 1033420 1033421]\n",
      "[   1606    1607    1608 ... 1033398 1033399 1033400]\n",
      "[   1585    1586    1587 ... 1033377 1033378 1033379]\n",
      "[   1564    1565    1566 ... 1033356 1033357 1033358]\n",
      "[   1543    1544    1545 ... 1033335 1033336 1033337]\n",
      "[   1522    1523    1524 ... 1033314 1033315 1033316]\n",
      "[   1501    1502    1503 ... 1033293 1033294 1033295]\n",
      "[   1480    1481    1482 ... 1033272 1033273 1033274]\n",
      "[   1459    1460    1461 ... 1033251 1033252 1033253]\n",
      "[   1438    1439    1440 ... 1033230 1033231 1033232]\n",
      "[   1417    1418    1419 ... 1033209 1033210 1033211]\n",
      "[   1396    1397    1398 ... 1033188 1033189 1033190]\n",
      "[   1375    1376    1377 ... 1033167 1033168 1033169]\n",
      "[   1354    1355    1356 ... 1033146 1033147 1033148]\n",
      "[   1333    1334    1335 ... 1033125 1033126 1033127]\n",
      "[   1312    1313    1314 ... 1033104 1033105 1033106]\n",
      "[   1291    1292    1293 ... 1033083 1033084 1033085]\n",
      "[   1270    1271    1272 ... 1033062 1033063 1033064]\n",
      "[   1249    1250    1251 ... 1033041 1033042 1033043]\n",
      "[   1228    1229    1230 ... 1033020 1033021 1033022]\n",
      "[   1207    1208    1209 ... 1032999 1033000 1033001]\n",
      "[   1186    1187    1188 ... 1032978 1032979 1032980]\n",
      "[   1165    1166    1167 ... 1032957 1032958 1032959]\n",
      "[   1144    1145    1146 ... 1032936 1032937 1032938]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████████████████████████████████▎                           | 8/12 [04:57<02:05, 31.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    655     656     657 ... 1024645 1024646 1024647]\n",
      "[    592     593     594 ... 1024582 1024583 1024584]\n",
      "[    529     530     531 ... 1024519 1024520 1024521]\n",
      "[    466     467     468 ... 1024456 1024457 1024458]\n",
      "[    403     404     405 ... 1024393 1024394 1024395]\n",
      "[    340     341     342 ... 1024330 1024331 1024332]\n",
      "[    277     278     279 ... 1024267 1024268 1024269]\n",
      "[    214     215     216 ... 1024204 1024205 1024206]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|██████████████████████████████████████████████████████████████▎                    | 9/12 [05:30<01:34, 31.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    697     698     699 ... 1024687 1024688 1024689]\n",
      "[    676     677     678 ... 1024666 1024667 1024668]\n",
      "[    655     656     657 ... 1024645 1024646 1024647]\n",
      "[    634     635     636 ... 1024624 1024625 1024626]\n",
      "[    613     614     615 ... 1024603 1024604 1024605]\n",
      "[    592     593     594 ... 1024582 1024583 1024584]\n",
      "[    571     572     573 ... 1024561 1024562 1024563]\n",
      "[    550     551     552 ... 1024540 1024541 1024542]\n",
      "[    529     530     531 ... 1024519 1024520 1024521]\n",
      "[    508     509     510 ... 1024498 1024499 1024500]\n",
      "[    487     488     489 ... 1024477 1024478 1024479]\n",
      "[    466     467     468 ... 1024456 1024457 1024458]\n",
      "[    445     446     447 ... 1024435 1024436 1024437]\n",
      "[    424     425     426 ... 1024414 1024415 1024416]\n",
      "[    403     404     405 ... 1024393 1024394 1024395]\n",
      "[    382     383     384 ... 1024372 1024373 1024374]\n",
      "[    361     362     363 ... 1024351 1024352 1024353]\n",
      "[    340     341     342 ... 1024330 1024331 1024332]\n",
      "[    319     320     321 ... 1024309 1024310 1024311]\n",
      "[    298     299     300 ... 1024288 1024289 1024290]\n",
      "[    277     278     279 ... 1024267 1024268 1024269]\n",
      "[    256     257     258 ... 1024246 1024247 1024248]\n",
      "[    235     236     237 ... 1024225 1024226 1024227]\n",
      "[    214     215     216 ... 1024204 1024205 1024206]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████████████▎             | 10/12 [07:04<01:41, 50.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1537    1538    1539 ... 1024645 1024646 1024647]\n",
      "[   1474    1475    1476 ... 1024582 1024583 1024584]\n",
      "[   1411    1412    1413 ... 1024519 1024520 1024521]\n",
      "[   1348    1349    1350 ... 1024456 1024457 1024458]\n",
      "[   1285    1286    1287 ... 1024393 1024394 1024395]\n",
      "[   1222    1223    1224 ... 1024330 1024331 1024332]\n",
      "[   1159    1160    1161 ... 1024267 1024268 1024269]\n",
      "[   1096    1097    1098 ... 1024204 1024205 1024206]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████▏      | 11/12 [07:12<00:37, 37.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1579    1580    1581 ... 1024687 1024688 1024689]\n",
      "[   1558    1559    1560 ... 1024666 1024667 1024668]\n",
      "[   1537    1538    1539 ... 1024645 1024646 1024647]\n",
      "[   1516    1517    1518 ... 1024624 1024625 1024626]\n",
      "[   1495    1496    1497 ... 1024603 1024604 1024605]\n",
      "[   1474    1475    1476 ... 1024582 1024583 1024584]\n",
      "[   1453    1454    1455 ... 1024561 1024562 1024563]\n",
      "[   1432    1433    1434 ... 1024540 1024541 1024542]\n",
      "[   1411    1412    1413 ... 1024519 1024520 1024521]\n",
      "[   1390    1391    1392 ... 1024498 1024499 1024500]\n",
      "[   1369    1370    1371 ... 1024477 1024478 1024479]\n",
      "[   1348    1349    1350 ... 1024456 1024457 1024458]\n",
      "[   1327    1328    1329 ... 1024435 1024436 1024437]\n",
      "[   1306    1307    1308 ... 1024414 1024415 1024416]\n",
      "[   1285    1286    1287 ... 1024393 1024394 1024395]\n",
      "[   1264    1265    1266 ... 1024372 1024373 1024374]\n",
      "[   1243    1244    1245 ... 1024351 1024352 1024353]\n",
      "[   1222    1223    1224 ... 1024330 1024331 1024332]\n",
      "[   1201    1202    1203 ... 1024309 1024310 1024311]\n",
      "[   1180    1181    1182 ... 1024288 1024289 1024290]\n",
      "[   1159    1160    1161 ... 1024267 1024268 1024269]\n",
      "[   1138    1139    1140 ... 1024246 1024247 1024248]\n",
      "[   1117    1118    1119 ... 1024225 1024226 1024227]\n",
      "[   1096    1097    1098 ... 1024204 1024205 1024206]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [07:31<00:00, 37.66s/it]\n"
     ]
    }
   ],
   "source": [
    "lr_metrics = []\n",
    "\n",
    "# iterate over our three CV configuration parameters\n",
    "for lookahead, train_length, test_length in tqdm(test_params):\n",
    "    label = f'r{lookahead:02}_fwd'\n",
    "    df = pd.get_dummies(data.loc[:, features + [label]].dropna(), \n",
    "                        columns=categoricals, \n",
    "                        drop_first=True)\n",
    "    X, y = df.drop(label, axis=1), df[label]\n",
    "\n",
    "    n_splits = int(2 * YEAR / test_length)\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              test_period_length=test_length,\n",
    "                              lookahead=lookahead,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    ic, preds = [], []\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X=X)):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_pred = lr.predict(X_test)\n",
    "        preds.append(y_test.to_frame('y_true').assign(y_pred=y_pred))\n",
    "        ic.append(spearmanr(y_test, y_pred)[0])\n",
    "    preds = pd.concat(preds)\n",
    "    lr_metrics.append([lookahead, \n",
    "                       train_length, \n",
    "                       test_length,\n",
    "                       np.mean(ic),\n",
    "                       spearmanr(preds.y_true, preds.y_pred)[0]\n",
    "                      ])\n",
    "\n",
    "columns = ['lookahead', 'train_length', 'test_length', 'ic_by_day', 'ic']\n",
    "lr_metrics = pd.DataFrame(lr_metrics, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Coefficient - Distribution by Lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.897475Z",
     "start_time": "2020-06-21T03:19:37.680445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(14,5), sharey=True)\n",
    "\n",
    "# plot average of daily IC values\n",
    "sns.boxplot(x='lookahead', y='ic_by_day',data=lr_metrics, ax=axes[0])\n",
    "axes[0].set_title('IC by Day')\n",
    "\n",
    "# plot IC across all predictions\n",
    "sns.boxplot(x='lookahead', y='ic',data=lr_metrics, ax=axes[1])\n",
    "axes[1].set_title('IC Overall')\n",
    "axes[0].set_ylabel('Information Coefficient')\n",
    "axes[1].set_ylabel('')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Train/Test Period Lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one- and five-day return forecasts, shorter train- and test-length yield better results in terms of daily avg IC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.911949Z",
     "start_time": "2020-06-21T03:19:37.898655Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lookahead</th>\n",
       "      <th>train_length</th>\n",
       "      <th>test_length</th>\n",
       "      <th>ic_by_day</th>\n",
       "      <th>ic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1134</td>\n",
       "      <td>63</td>\n",
       "      <td>0.057549</td>\n",
       "      <td>0.054526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1134</td>\n",
       "      <td>21</td>\n",
       "      <td>0.056295</td>\n",
       "      <td>0.043302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>63</td>\n",
       "      <td>0.044716</td>\n",
       "      <td>0.028831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>252</td>\n",
       "      <td>21</td>\n",
       "      <td>0.068885</td>\n",
       "      <td>0.021455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1134</td>\n",
       "      <td>21</td>\n",
       "      <td>0.060347</td>\n",
       "      <td>0.032623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1134</td>\n",
       "      <td>63</td>\n",
       "      <td>0.055092</td>\n",
       "      <td>0.045973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>1134</td>\n",
       "      <td>21</td>\n",
       "      <td>0.070776</td>\n",
       "      <td>0.020801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21</td>\n",
       "      <td>252</td>\n",
       "      <td>21</td>\n",
       "      <td>0.055217</td>\n",
       "      <td>-0.003813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>1134</td>\n",
       "      <td>63</td>\n",
       "      <td>0.054429</td>\n",
       "      <td>0.022415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lookahead  train_length  test_length  ic_by_day        ic\n",
       "0           1          1134           63   0.057549  0.054526\n",
       "1           1          1134           21   0.056295  0.043302\n",
       "2           1           252           63   0.044716  0.028831\n",
       "7           5           252           21   0.068885  0.021455\n",
       "5           5          1134           21   0.060347  0.032623\n",
       "4           5          1134           63   0.055092  0.045973\n",
       "9          21          1134           21   0.070776  0.020801\n",
       "11         21           252           21   0.055217 -0.003813\n",
       "8          21          1134           63   0.054429  0.022415"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lr_metrics.groupby('lookahead', group_keys=False)\n",
    " .apply(lambda x: x.nlargest(3, 'ic_by_day')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.920850Z",
     "start_time": "2020-06-21T03:19:37.913179Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_metrics.to_csv(results_path / 'lin_reg_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook example iterates over many configurations, optionally using random samples to speed up model selection using a diverse subset. The goal is to identify the most impactful parameters without trying every possible combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.935808Z",
     "start_time": "2020-06-21T03:19:37.921761Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_fi(model):\n",
    "    \"\"\"Return normalized feature importance as pd.Series\"\"\"\n",
    "    fi = model.feature_importance(importance_type='gain')\n",
    "    return (pd.Series(fi / fi.sum(),\n",
    "                      index=model.feature_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `base_params` are not affected by cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.943601Z",
     "start_time": "2020-06-21T03:19:37.936926Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_params = dict(boosting='gbdt',\n",
    "                   objective='regression',\n",
    "                   verbose=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the following parameters and values to select our best model (see book chapter for detail):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.952308Z",
     "start_time": "2020-06-21T03:19:37.944671Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# constraints on structure (depth) of each tree\n",
    "max_depths = [2, 3, 5, 7]\n",
    "num_leaves_opts = [2 ** i for i in max_depths]\n",
    "min_data_in_leaf_opts = [250, 500, 1000]\n",
    "\n",
    "# weight of each new tree in the ensemble\n",
    "learning_rate_ops = [.01, .1, .3]\n",
    "\n",
    "# random feature selection\n",
    "feature_fraction_opts = [.3, .6, .95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.960258Z",
     "start_time": "2020-06-21T03:19:37.953744Z"
    }
   },
   "outputs": [],
   "source": [
    "param_names = ['learning_rate', 'num_leaves',\n",
    "               'feature_fraction', 'min_data_in_leaf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.969006Z",
     "start_time": "2020-06-21T03:19:37.961383Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Parameters: 108\n"
     ]
    }
   ],
   "source": [
    "cv_params = list(product(learning_rate_ops,\n",
    "                         num_leaves_opts,\n",
    "                         feature_fraction_opts,\n",
    "                         min_data_in_leaf_opts))\n",
    "n_params = len(cv_params)\n",
    "print(f'# Parameters: {n_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Period Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.977749Z",
     "start_time": "2020-06-21T03:19:37.969903Z"
    }
   },
   "outputs": [],
   "source": [
    "lookaheads = [1, 5, 21]\n",
    "# lookaheads = [1]\n",
    "label_dict = dict(zip(lookaheads, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only use test periods of 63 days length to save some model training and evaluation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.986465Z",
     "start_time": "2020-06-21T03:19:37.978744Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_lengths = [int(4.5 * 252), 252]\n",
    "test_lengths = [63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.995277Z",
     "start_time": "2020-06-21T03:19:37.987379Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train configs: 6\n"
     ]
    }
   ],
   "source": [
    "test_params = list(product(lookaheads, train_lengths, test_lengths))\n",
    "n = len(test_params)\n",
    "test_param_sample = np.random.choice(list(range(n)), size=int(n), replace=False)\n",
    "test_params = [test_params[i] for i in test_param_sample]\n",
    "print('Train configs:', len(test_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We integer-encode categorical variables with values starting at zero, as expected by LightGBM (not necessary\n",
    "as long as the category codes have values less than $2^{32}$, but avoids a warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.043537Z",
     "start_time": "2020-06-21T03:19:37.996178Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categoricals = ['year', 'weekday', 'month']\n",
    "for feature in categoricals:\n",
    "    data[feature] = pd.factorize(data[feature], sort=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Function: Information Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.046578Z",
     "start_time": "2020-06-21T03:19:38.044405Z"
    }
   },
   "outputs": [],
   "source": [
    "def ic_lgbm(preds, train_data):\n",
    "    \"\"\"Custom IC eval metric for lightgbm\"\"\"\n",
    "    is_higher_better = True\n",
    "    return 'ic', spearmanr(preds, train_data.get_label())[0], is_higher_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore the hyperparameter space, we specify values for key parameters that we would like to test in combination. The sklearn library supports `RandomizedSearchCV` to cross-validate a subset of parameter combinations that are sampled randomly from specified distributions. We will implement a custom version that allows us to monitor performance so we can abort the search process once we're satisfied with the result, rather than specifying a set number of iterations beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.054547Z",
     "start_time": "2020-06-21T03:19:38.047670Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb_store = Path(results_path / 'tuning_lgb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.070171Z",
     "start_time": "2020-06-21T03:19:38.055637Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = sorted(data.filter(like='fwd').columns)\n",
    "features = data.columns.difference(labels).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.078077Z",
     "start_time": "2020-06-21T03:19:38.071079Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_dict = dict(zip(lookaheads, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.086476Z",
     "start_time": "2020-06-21T03:19:38.078921Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_iterations = [10, 25, 50, 75] + list(range(100, 501, 50))\n",
    "num_boost_round = num_iterations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.094204Z",
     "start_time": "2020-06-21T03:19:38.087354Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_cols = (param_names + ['t', 'daily_ic_mean', 'daily_ic_mean_n',\n",
    "                              'daily_ic_median', 'daily_ic_median_n'] +\n",
    "               [str(n) for n in num_iterations])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over our six CV configurations and collect the resulting metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.000694Z",
     "start_time": "2020-06-21T03:19:38.095078Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookahead:  1 | Train: 1134 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:00:42 ( 42) |  0.30 |   4 | 95% | 1000 |   7.38% |  6.93% |  200 |  7.35% |  200\n",
      "\t  1 | 00:01:19 ( 37) |  0.01 |   4 | 60% |  500 |   5.26% |  5.13% |  500 |  5.28% |  500\n",
      "\t  2 | 00:01:55 ( 36) |  0.10 |   4 | 60% |  500 |   7.91% |  7.21% |  500 |  7.49% |  500\n",
      "\t  3 | 00:03:23 ( 89) |  0.10 | 128 | 95% |  250 |   7.09% |  7.18% |  100 |  7.36% |  150\n",
      "\t  4 | 00:04:07 ( 43) |  0.01 |   8 | 30% |  500 |   6.40% |  5.88% |  500 |  5.79% |  500\n",
      "\t  5 | 00:04:46 ( 39) |  0.10 |   8 | 30% |  250 |   8.58% |  7.68% |  500 |  8.16% |  300\n",
      "\t  6 | 00:06:25 (100) |  0.10 | 128 | 95% |  500 |   7.20% |  7.04% |  100 |  6.97% |  300\n",
      "\t  7 | 00:07:33 ( 68) |  0.10 | 128 | 60% |  250 |   7.37% |  7.37% |   75 |  7.69% |   75\n",
      "\t  8 | 00:08:17 ( 44) |  0.10 |   8 | 30% | 1000 |   8.59% |  7.56% |  450 |  7.85% |  250\n",
      "\t  9 | 00:08:60 ( 43) |  0.01 |   8 | 30% | 1000 |   6.57% |  5.99% |  500 |  5.83% |  500\n",
      "\t 10 | 00:09:59 ( 60) |  0.30 |  32 | 95% | 1000 |   7.38% |  6.46% |   50 |  6.62% |   25\n",
      "\t 11 | 00:10:38 ( 39) |  0.10 |   4 | 30% |  250 |   8.12% |  7.30% |  500 |  7.80% |  500\n",
      "\t 12 | 00:11:16 ( 38) |  0.30 |   8 | 30% | 1000 |   8.37% |  7.45% |  200 |  7.79% |  250\n",
      "\t 13 | 00:11:56 ( 41) |  0.10 |   8 | 95% |  250 |   7.76% |  7.28% |  450 |  7.72% |  350\n",
      "\t 14 | 00:12:48 ( 52) |  0.01 |  32 | 30% |  250 |   7.69% |  7.10% |  500 |  7.02% |  500\n",
      "\t 15 | 00:13:23 ( 35) |  0.01 |   4 | 30% |  250 |   5.34% |  5.03% |  500 |  4.59% |  500\n",
      "\t 16 | 00:13:58 ( 35) |  0.30 |   4 | 30% |  250 |   7.98% |  7.27% |  350 |  7.43% |  350\n",
      "\t 17 | 00:15:13 ( 75) |  0.01 |  32 | 95% | 1000 |   7.10% |  7.11% |  500 |  7.25% |  500\n",
      "\t 18 | 00:15:48 ( 36) |  0.30 |   8 | 30% |  250 |   7.66% |  6.91% |  300 |  7.07% |  100\n",
      "\t 19 | 00:16:31 ( 43) |  0.10 |   8 | 95% | 1000 |   7.70% |  7.39% |  500 |  7.65% |  300\n",
      "\t 20 | 00:17:31 ( 60) |  0.30 | 128 | 60% |  500 |   6.33% |  6.25% |   25 |  6.52% |   25\n",
      "\t 21 | 00:18:16 ( 45) |  0.30 |  32 | 30% |  500 |   7.67% |  6.93% |   75 |  6.65% |   50\n",
      "\t 22 | 00:18:54 ( 38) |  0.01 |   8 | 60% |  250 |   6.32% |  5.86% |  500 |  6.19% |  500\n",
      "\t 23 | 00:20:20 ( 86) |  0.01 | 128 | 60% |  500 |   7.78% |  7.88% |  500 |  7.91% |  500\n",
      "\t 24 | 00:21:23 ( 63) |  0.10 | 128 | 60% |  500 |   7.59% |  7.33% |  150 |  7.73% |  250\n",
      "\t 25 | 00:22:09 ( 46) |  0.30 |  32 | 30% | 1000 |   7.86% |  6.84% |  100 |  6.99% |  100\n",
      "\t 26 | 00:23:51 (102) |  0.10 | 128 | 95% | 1000 |   7.62% |  7.24% |  100 |  7.55% |   50\n",
      "\t 27 | 00:24:45 ( 54) |  0.01 |  32 | 60% |  500 |   7.26% |  7.09% |  500 |  7.34% |  500\n",
      "\t 28 | 00:25:23 ( 38) |  0.10 |   4 | 95% | 1000 |   7.26% |  7.07% |  400 |  7.43% |  500\n",
      "\t 29 | 00:27:04 (101) |  0.30 | 128 | 95% | 1000 |   6.78% |  5.99% |   25 |  5.84% |   25\n",
      "\t 30 | 00:27:45 ( 41) |  0.30 |   4 | 95% |  250 |   7.22% |  6.90% |  250 |  7.52% |  200\n",
      "\t 31 | 00:28:37 ( 51) |  0.01 |   8 | 95% |  250 |   6.44% |  5.96% |  500 |  6.22% |  500\n",
      "\t 32 | 00:30:26 (110) |  0.01 | 128 | 60% |  250 |   7.67% |  7.82% |  500 |  8.11% |  500\n",
      "\t 33 | 00:32:04 ( 97) |  0.30 | 128 | 60% | 1000 |   7.25% |  6.21% |   25 |  6.46% |   25\n",
      "\t 34 | 00:32:49 ( 45) |  0.01 |   8 | 30% |  250 |   6.25% |  5.83% |  500 |  5.91% |  500\n",
      "\t 35 | 00:34:45 (115) |  0.01 | 128 | 95% |  250 |   7.32% |  7.58% |  500 |  7.75% |  500\n",
      "\t 36 | 00:35:48 ( 63) |  0.10 |  32 | 95% | 1000 |   7.45% |  7.21% |  250 |  7.60% |  150\n",
      "\t 37 | 00:37:15 ( 87) |  0.10 | 128 | 30% | 1000 |   8.42% |  7.57% |  150 |  7.64% |   50\n",
      "\t 38 | 00:38:41 ( 87) |  0.01 | 128 | 30% |  500 |   8.43% |  7.96% |  500 |  8.16% |  450\n",
      "\t 39 | 00:39:25 ( 43) |  0.10 |   4 | 95% |  250 |   7.72% |  7.02% |  500 |  7.39% |  450\n",
      "\t 40 | 00:40:03 ( 39) |  0.01 |   4 | 60% | 1000 |   5.30% |  5.15% |  500 |  5.14% |  500\n",
      "\t 41 | 00:40:56 ( 53) |  0.10 |  32 | 30% |  500 |   8.42% |  7.63% |  200 |  7.79% |  200\n",
      "\t 42 | 00:42:16 ( 79) |  0.10 | 128 | 30% |  500 |   8.47% |  7.63% |  150 |  7.83% |  100\n",
      "\t 43 | 00:42:53 ( 37) |  0.10 |   4 | 60% |  250 |   7.97% |  7.12% |  500 |  7.48% |  450\n",
      "\t 44 | 00:45:04 (131) |  0.01 | 128 | 95% | 1000 |   7.68% |  7.71% |  500 |  8.01% |  500\n",
      "\t 45 | 00:45:57 ( 53) |  0.01 |   8 | 95% |  500 |   6.53% |  5.99% |  500 |  6.36% |  500\n",
      "\t 46 | 00:47:09 ( 73) |  0.30 | 128 | 30% | 1000 |   7.50% |  6.26% |   50 |  6.40% |   50\n",
      "\t 47 | 00:49:01 (111) |  0.01 | 128 | 95% |  500 |   7.55% |  7.59% |  500 |  7.57% |  500\n",
      "\t 48 | 00:49:47 ( 46) |  0.10 |  32 | 30% | 1000 |   8.99% |  8.00% |  350 |  8.29% |  250\n",
      "\t 49 | 00:50:24 ( 37) |  0.01 |   4 | 95% |  500 |   5.34% |  5.12% |  500 |  5.22% |  500\n",
      "\t 50 | 00:51:00 ( 36) |  0.10 |   4 | 95% |  500 |   7.48% |  7.20% |  500 |  7.55% |  500\n",
      "\t 51 | 00:52:15 ( 74) |  0.10 | 128 | 60% | 1000 |   8.16% |  7.62% |   75 |  7.86% |  100\n",
      "\t 52 | 00:52:50 ( 36) |  0.30 |   8 | 60% |  500 |   7.76% |  7.15% |  150 |  7.68% |  250\n",
      "\t 53 | 00:54:04 ( 74) |  0.01 | 128 | 30% |  250 |   8.22% |  7.86% |  500 |  8.26% |  500\n",
      "Lookahead:  1 | Train: 252 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:00:18 ( 18) |  0.01 |   8 | 95% |  250 |   3.57% |  4.18% |  500 |  4.16% |  500\n",
      "\t  1 | 00:00:33 ( 16) |  0.01 |   8 | 30% |  250 |   4.11% |  4.51% |  500 |  4.35% |  500\n",
      "\t  2 | 00:01:15 ( 41) |  0.30 | 128 | 30% |  500 |   5.12% |  4.16% |   10 |  4.13% |   25\n",
      "\t  3 | 00:01:29 ( 14) |  0.30 |   8 | 30% |  250 |   5.33% |  4.85% |  100 |  4.63% |  150\n",
      "\t  4 | 00:02:05 ( 36) |  0.10 | 128 | 60% | 1000 |   4.90% |  5.13% |   75 |  5.38% |   75\n",
      "\t  5 | 00:02:26 ( 21) |  0.30 |  32 | 60% | 1000 |   4.69% |  4.95% |   50 |  4.98% |  100\n",
      "\t  6 | 00:02:48 ( 22) |  0.10 |  32 | 60% | 1000 |   5.34% |  5.52% |  150 |  5.49% |  400\n",
      "\t  7 | 00:03:07 ( 19) |  0.01 |   8 | 95% | 1000 |   3.79% |  4.19% |  500 |  4.14% |  500\n",
      "\t  8 | 00:03:24 ( 17) |  0.10 |   8 | 60% |  500 |   4.78% |  5.24% |  500 |  5.40% |  500\n",
      "\t  9 | 00:03:40 ( 16) |  0.10 |   4 | 30% |  500 |   5.01% |  5.02% |  450 |  4.85% |  450\n",
      "\t 10 | 00:04:23 ( 43) |  0.30 | 128 | 30% |  250 |   4.49% |  3.93% |   10 |  4.01% |  150\n",
      "\t 11 | 00:04:51 ( 29) |  0.01 |  32 | 30% | 1000 |   5.09% |  5.66% |  450 |  5.65% |  500\n",
      "\t 12 | 00:05:34 ( 43) |  0.10 | 128 | 30% | 1000 |   5.56% |  5.44% |  150 |  5.19% |   50\n",
      "\t 13 | 00:05:51 ( 17) |  0.10 |   8 | 60% |  250 |   4.70% |  5.06% |  500 |  5.05% |  500\n",
      "\t 14 | 00:06:06 ( 15) |  0.30 |   4 | 30% |  500 |   4.57% |  4.78% |  200 |  4.63% |  250\n",
      "\t 15 | 00:06:28 ( 22) |  0.30 |  32 | 30% |  500 |   4.96% |  4.42% |   25 |  4.27% |   50\n",
      "\t 16 | 00:06:51 ( 23) |  0.01 |  32 | 30% |  250 |   4.76% |  5.46% |  500 |  5.28% |  500\n",
      "\t 17 | 00:07:07 ( 16) |  0.30 |   8 | 30% |  500 |   4.98% |  4.90% |  200 |  4.80% |  150\n",
      "\t 18 | 00:07:24 ( 17) |  0.30 |   8 | 60% | 1000 |   4.53% |  4.52% |   75 |  4.75% |   75\n",
      "\t 19 | 00:07:39 ( 15) |  0.10 |   4 | 60% |  250 |   4.66% |  4.89% |  500 |  4.60% |  150\n",
      "\t 20 | 00:08:02 ( 24) |  0.10 |  32 | 95% |  250 |   4.99% |  4.92% |  300 |  4.84% |  350\n",
      "\t 21 | 00:08:41 ( 38) |  0.30 | 128 | 30% | 1000 |   5.42% |  4.65% |   10 |  4.59% |   10\n",
      "\t 22 | 00:09:06 ( 25) |  0.30 |  32 | 95% | 1000 |   4.71% |  4.60% |   50 |  4.76% |  100\n",
      "\t 23 | 00:09:45 ( 39) |  0.01 | 128 | 60% |  250 |   4.64% |  5.63% |  500 |  5.27% |  400\n",
      "\t 24 | 00:10:13 ( 28) |  0.01 |  32 | 95% |  500 |   4.12% |  4.90% |  500 |  5.06% |  500\n",
      "\t 25 | 00:10:32 ( 20) |  0.01 |   8 | 95% |  500 |   3.62% |  4.27% |  500 |  4.09% |  400\n",
      "\t 26 | 00:11:13 ( 41) |  0.10 | 128 | 30% |  250 |   5.08% |  4.96% |  150 |  5.18% |  200\n",
      "\t 27 | 00:11:31 ( 17) |  0.30 |   8 | 95% |  500 |   4.30% |  4.31% |  100 |  4.43% |  100\n",
      "\t 28 | 00:11:54 ( 24) |  0.30 |  32 | 95% |  500 |   4.72% |  4.33% |  100 |  4.51% |  150\n",
      "\t 29 | 00:12:09 ( 15) |  0.30 |   4 | 30% | 1000 |   4.63% |  4.82% |  450 |  4.93% |  450\n",
      "\t 30 | 00:12:51 ( 42) |  0.10 | 128 | 60% |  500 |   4.90% |  5.15% |   75 |  5.27% |   50\n",
      "\t 31 | 00:13:43 ( 52) |  0.10 | 128 | 95% |  500 |   5.12% |  5.15% |   75 |  5.27% |   75\n",
      "\t 32 | 00:14:09 ( 26) |  0.01 |  32 | 60% | 1000 |   4.35% |  5.18% |  500 |  5.50% |  500\n",
      "\t 33 | 00:14:34 ( 25) |  0.30 |  32 | 30% | 1000 |   4.94% |  4.62% |   50 |  4.43% |  200\n",
      "\t 34 | 00:14:50 ( 16) |  0.30 |   4 | 95% |  500 |   4.34% |  4.76% |  350 |  4.81% |  350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 35 | 00:15:36 ( 47) |  0.10 | 128 | 95% |  250 |   4.72% |  4.87% |  100 |  5.03% |  100\n",
      "\t 36 | 00:15:53 ( 16) |  0.01 |   4 | 95% |  500 |   2.94% |  3.40% |  500 |  3.08% |  500\n",
      "\t 37 | 00:16:15 ( 23) |  0.10 |  32 | 30% |  500 |   5.37% |  5.51% |  200 |  5.08% |  200\n",
      "\t 38 | 00:16:31 ( 16) |  0.10 |   8 | 30% |  250 |   5.11% |  5.33% |  450 |  5.45% |  450\n",
      "\t 39 | 00:16:48 ( 16) |  0.30 |   8 | 60% |  250 |   4.56% |  4.63% |   75 |  4.71% |  200\n",
      "\t 40 | 00:17:29 ( 42) |  0.30 | 128 | 60% |  500 |   4.29% |  4.12% |   25 |  3.98% |   25\n",
      "\t 41 | 00:18:08 ( 38) |  0.10 | 128 | 60% |  250 |   4.85% |  5.06% |  100 |  4.93% |   50\n",
      "\t 42 | 00:18:24 ( 16) |  0.30 |   4 | 95% | 1000 |   4.20% |  4.51% |  400 |  4.58% |  500\n",
      "\t 43 | 00:18:40 ( 16) |  0.30 |   8 | 30% | 1000 |   5.22% |  4.84% |  200 |  5.01% |  300\n",
      "\t 44 | 00:19:03 ( 22) |  0.30 |  32 | 95% |  250 |   4.36% |  4.01% |   50 |  4.07% |   50\n",
      "\t 45 | 00:19:18 ( 15) |  0.10 |   4 | 30% | 1000 |   5.14% |  5.02% |  500 |  4.70% |  500\n",
      "\t 46 | 00:19:44 ( 26) |  0.01 |  32 | 95% |  250 |   4.40% |  5.03% |  500 |  4.81% |  350\n",
      "\t 47 | 00:20:03 ( 19) |  0.10 |   8 | 95% | 1000 |   4.61% |  4.91% |  500 |  4.94% |  500\n",
      "\t 48 | 00:20:21 ( 18) |  0.01 |   8 | 30% |  500 |   4.08% |  4.50% |  500 |  4.01% |  400\n",
      "\t 49 | 00:20:59 ( 38) |  0.01 | 128 | 30% | 1000 |   5.60% |  6.11% |  450 |  6.21% |  400\n",
      "\t 50 | 00:21:22 ( 24) |  0.01 |  32 | 30% |  500 |   4.95% |  5.56% |  500 |  5.37% |  500\n",
      "\t 51 | 00:21:43 ( 21) |  0.10 |  32 | 60% |  250 |   5.01% |  5.22% |  250 |  5.14% |  250\n",
      "\t 52 | 00:22:05 ( 21) |  0.30 |  32 | 30% |  250 |   4.99% |  4.65% |  150 |  4.60% |  150\n",
      "\t 53 | 00:22:25 ( 20) |  0.10 |  32 | 30% |  250 |   5.35% |  5.70% |  200 |  5.72% |  250\n",
      "Lookahead: 21 | Train: 252 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:00:40 ( 40) |  0.30 | 128 | 30% |  500 |   3.99% |  4.27% |   25 |  4.38% |   25\n",
      "\t  1 | 00:01:21 ( 41) |  0.01 | 128 | 30% |  250 |   2.06% |  4.78% |  400 |  5.31% |  400\n",
      "\t  2 | 00:02:01 ( 40) |  0.01 | 128 | 95% |  250 |   3.00% |  4.41% |  400 |  4.34% |  350\n",
      "\t  3 | 00:02:19 ( 18) |  0.01 |   8 | 60% |  250 |   2.50% |  6.09% |  350 |  6.48% |  400\n",
      "\t  4 | 00:02:35 ( 16) |  0.30 |   8 | 60% |  250 |   4.35% |  6.98% |   25 |  6.52% |   25\n",
      "\t  5 | 00:03:06 ( 31) |  0.30 | 128 | 60% |  250 |   4.57% |  3.64% |   25 |  3.34% |   10\n",
      "\t  6 | 00:03:42 ( 36) |  0.01 | 128 | 30% | 1000 |   2.15% |  5.01% |  500 |  5.49% |   75\n",
      "\t  7 | 00:03:57 ( 15) |  0.01 |   8 | 30% |  250 |   0.30% |  5.06% |  500 |  5.34% |  500\n",
      "\t  8 | 00:04:20 ( 23) |  0.30 |  32 | 95% | 1000 |   5.60% |  5.51% |   10 |  5.62% |   10\n",
      "\t  9 | 00:04:35 ( 15) |  0.01 |   4 | 60% | 1000 |   3.33% |  5.49% |   25 |  5.15% |   75\n",
      "\t 10 | 00:04:49 ( 15) |  0.30 |   4 | 60% | 1000 |   5.89% |  5.65% |  100 |  4.81% |   75\n",
      "\t 11 | 00:05:28 ( 38) |  0.30 | 128 | 95% | 1000 |   4.78% |  3.86% |   10 |  3.13% |   25\n",
      "\t 12 | 00:06:08 ( 40) |  0.10 | 128 | 30% |  500 |   3.41% |  4.58% |   50 |  4.58% |   25\n",
      "\t 13 | 00:06:25 ( 17) |  0.01 |   8 | 60% | 1000 |   2.47% |  6.17% |  350 |  6.28% |  350\n",
      "\t 14 | 00:06:47 ( 22) |  0.01 |  32 | 30% | 1000 |   1.63% |  5.35% |  400 |  5.71% |  500\n",
      "\t 15 | 00:07:13 ( 26) |  0.01 |  32 | 95% | 1000 |   2.59% |  4.75% |  400 |  4.66% |  400\n",
      "\t 16 | 00:07:27 ( 14) |  0.30 |   8 | 30% |  250 |   4.76% |  5.40% |  100 |  6.20% |  100\n",
      "\t 17 | 00:07:42 ( 15) |  0.10 |   4 | 95% |  250 |   5.38% |  6.90% |   10 |  6.12% |   10\n",
      "\t 18 | 00:08:07 ( 24) |  0.01 |  32 | 95% |  500 |   3.01% |  4.83% |  450 |  4.34% |  450\n",
      "\t 19 | 00:08:28 ( 21) |  0.30 |  32 | 60% | 1000 |   4.78% |  4.61% |   25 |  4.47% |   25\n",
      "\t 20 | 00:08:45 ( 17) |  0.30 |   8 | 95% |  500 |   4.32% |  6.23% |   25 |  6.57% |   25\n",
      "\t 21 | 00:09:00 ( 15) |  0.10 |   4 | 95% | 1000 |   5.20% |  6.21% |   10 |  6.73% |   10\n",
      "\t 22 | 00:09:22 ( 22) |  0.10 |  32 | 95% |  500 |   4.68% |  5.43% |   50 |  4.96% |   75\n",
      "\t 23 | 00:09:37 ( 15) |  0.01 |   4 | 60% |  250 |   3.49% |  5.52% |   25 |  5.01% |   25\n",
      "\t 24 | 00:10:11 ( 34) |  0.30 | 128 | 30% |  250 |   4.07% |  4.33% |   25 |  4.46% |   25\n",
      "\t 25 | 00:10:26 ( 15) |  0.30 |   4 | 95% |  250 |   5.65% |  5.77% |   50 |  5.71% |  500\n",
      "\t 26 | 00:11:04 ( 38) |  0.10 | 128 | 30% |  250 |   3.33% |  4.54% |   25 |  4.71% |   25\n",
      "\t 27 | 00:11:26 ( 22) |  0.01 |  32 | 60% |  250 |   2.69% |  5.88% |  150 |  6.42% |  150\n",
      "\t 28 | 00:11:50 ( 23) |  0.10 |  32 | 95% | 1000 |   4.97% |  5.15% |   75 |  4.65% |   10\n",
      "\t 29 | 00:12:04 ( 15) |  0.10 |   8 | 30% |  250 |   3.21% |  4.84% |  500 |  4.91% |  100\n",
      "\t 30 | 00:12:21 ( 17) |  0.01 |   8 | 60% |  500 |   2.46% |  6.22% |  500 |  6.34% |  400\n",
      "\t 31 | 00:12:59 ( 38) |  0.10 | 128 | 95% | 1000 |   3.88% |  3.91% |   75 |  3.53% |  200\n",
      "\t 32 | 00:13:17 ( 18) |  0.01 |   8 | 95% | 1000 |   3.70% |  6.50% |  500 |  6.10% |  400\n",
      "\t 33 | 00:13:57 ( 40) |  0.01 | 128 | 30% |  500 |   2.31% |  4.86% |  500 |  5.22% |  300\n",
      "\t 34 | 00:14:17 ( 20) |  0.10 |  32 | 60% |  250 |   4.82% |  5.83% |   25 |  5.97% |   25\n",
      "\t 35 | 00:14:34 ( 17) |  0.10 |   8 | 95% | 1000 |   4.73% |  6.53% |   75 |  6.53% |   75\n",
      "\t 36 | 00:14:57 ( 23) |  0.01 |  32 | 95% |  250 |   3.36% |  5.20% |  400 |  5.20% |  500\n",
      "\t 37 | 00:15:14 ( 17) |  0.10 |   8 | 95% |  500 |   5.61% |  6.78% |   75 |  6.30% |   75\n",
      "\t 38 | 00:15:30 ( 16) |  0.10 |   8 | 60% | 1000 |   2.87% |  5.78% |  100 |  5.33% |  100\n",
      "\t 39 | 00:15:45 ( 14) |  0.30 |   4 | 60% |  250 |   5.93% |  6.66% |  100 |  6.31% |   75\n",
      "\t 40 | 00:16:06 ( 21) |  0.30 |  32 | 95% |  500 |   4.53% |  4.52% |   50 |  4.34% |   75\n",
      "\t 41 | 00:16:21 ( 15) |  0.30 |   8 | 30% | 1000 |   5.17% |  5.40% |   50 |  5.74% |   75\n",
      "\t 42 | 00:16:36 ( 16) |  0.01 |   4 | 95% |  500 |   4.56% |  8.98% |   10 |  8.14% |   25\n",
      "\t 43 | 00:16:55 ( 19) |  0.30 |  32 | 30% |  250 |   3.94% |  4.89% |   75 |  4.49% |   50\n",
      "\t 44 | 00:17:10 ( 15) |  0.10 |   8 | 30% |  500 |   3.20% |  4.82% |  250 |  4.74% |  250\n",
      "\t 45 | 00:17:24 ( 14) |  0.30 |   4 | 60% |  500 |   5.74% |  5.76% |  250 |  5.99% |   50\n",
      "\t 46 | 00:17:45 ( 20) |  0.30 |  32 | 95% |  250 |   5.51% |  5.26% |   25 |  4.89% |   25\n",
      "\t 47 | 00:18:01 ( 16) |  0.30 |   8 | 95% |  250 |   5.39% |  6.51% |   25 |  5.53% |   25\n",
      "\t 48 | 00:18:17 ( 16) |  0.30 |   8 | 60% | 1000 |   4.39% |  5.65% |   50 |  5.30% |  500\n",
      "\t 49 | 00:18:55 ( 38) |  0.10 | 128 | 30% | 1000 |   3.79% |  4.74% |   75 |  5.23% |   25\n",
      "\t 50 | 00:19:16 ( 21) |  0.10 |  32 | 95% |  250 |   5.42% |  5.66% |   75 |  6.42% |  100\n",
      "\t 51 | 00:19:32 ( 16) |  0.30 |   4 | 95% | 1000 |   5.05% |  5.40% |   10 |  5.01% |   10\n",
      "\t 52 | 00:20:14 ( 42) |  0.01 | 128 | 95% |  500 |   2.81% |  4.38% |  400 |  3.97% |  350\n",
      "\t 53 | 00:20:28 ( 14) |  0.10 |   4 | 60% |  500 |   4.22% |  6.21% |  150 |  5.66% |  100\n",
      "Lookahead:  5 | Train: 1134 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:00:32 ( 32) |  0.10 |   4 | 60% |  500 |   7.84% |  5.18% |  500 |  4.23% |  500\n",
      "\t  1 | 00:01:10 ( 38) |  0.10 |   8 | 95% |  250 |   7.84% |  5.27% |  250 |  4.59% |  300\n",
      "\t  2 | 00:01:50 ( 41) |  0.30 |  32 | 30% |  500 |   7.80% |  5.36% |  200 |  4.72% |  200\n",
      "\t  3 | 00:03:20 ( 90) |  0.10 | 128 | 95% | 1000 |   9.07% |  6.21% |  100 |  5.95% |  450\n",
      "\t  4 | 00:03:52 ( 32) |  0.01 |   4 | 30% | 1000 |   4.51% |  3.79% |  250 |  4.04% |  200\n",
      "\t  5 | 00:04:26 ( 33) |  0.30 |   8 | 30% |  250 |   7.29% |  6.03% |  250 |  5.37% |  500\n",
      "\t  6 | 00:05:07 ( 42) |  0.10 |  32 | 30% |  250 |   8.66% |  6.20% |  450 |  5.51% |  400\n",
      "\t  7 | 00:06:12 ( 65) |  0.30 | 128 | 60% | 1000 |   8.01% |  4.97% |   75 |  4.74% |  350\n",
      "\t  8 | 00:06:52 ( 40) |  0.30 |  32 | 60% |  500 |   8.32% |  5.33% |   75 |  4.39% |   75\n",
      "\t  9 | 00:07:42 ( 50) |  0.30 |  32 | 95% | 1000 |   9.45% |  5.48% |  100 |  5.06% |   75\n",
      "\t 10 | 00:08:55 ( 73) |  0.30 | 128 | 95% |  250 |   7.91% |  4.81% |   25 |  4.20% |   25\n",
      "\t 11 | 00:09:39 ( 44) |  0.10 |  32 | 30% | 1000 |   8.70% |  6.24% |  200 |  5.49% |  200\n",
      "\t 12 | 00:10:29 ( 51) |  0.10 |  32 | 95% |  500 |   8.93% |  5.39% |  250 |  5.05% |  500\n",
      "\t 13 | 00:11:12 ( 43) |  0.10 |  32 | 30% |  500 |   7.96% |  5.66% |  400 |  5.19% |  150\n",
      "\t 14 | 00:11:43 ( 31) |  0.30 |   4 | 60% |  500 |   8.91% |  5.35% |  500 |  4.50% |  500\n",
      "\t 15 | 00:12:15 ( 32) |  0.30 |   4 | 30% |  500 |   7.33% |  5.78% |  450 |  5.50% |  450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 16 | 00:12:57 ( 43) |  0.10 |  32 | 60% |  500 |   9.22% |  5.48% |  150 |  4.85% |  150\n",
      "\t 17 | 00:13:28 ( 31) |  0.01 |   4 | 60% |  500 |   5.20% |  4.08% |  450 |  3.30% |   25\n",
      "\t 18 | 00:14:04 ( 35) |  0.01 |   8 | 30% |  500 |   5.49% |  3.84% |  500 |  3.34% |  500\n",
      "\t 19 | 00:14:37 ( 33) |  0.30 |   8 | 60% |  500 |   8.83% |  5.48% |  500 |  5.00% |  400\n",
      "\t 20 | 00:15:11 ( 34) |  0.30 |   8 | 60% | 1000 |   7.88% |  5.47% |  200 |  4.88% |  300\n",
      "\t 21 | 00:15:46 ( 35) |  0.01 |   8 | 30% |  250 |   5.45% |  3.83% |  500 |  3.16% |  500\n",
      "\t 22 | 00:16:24 ( 37) |  0.30 |   8 | 95% | 1000 |   9.47% |  5.85% |  500 |  5.67% |  500\n",
      "\t 23 | 00:16:58 ( 34) |  0.30 |   4 | 95% | 1000 |   7.21% |  5.23% |  500 |  4.83% |  500\n",
      "\t 24 | 00:17:29 ( 31) |  0.30 |   4 | 30% |  250 |   6.93% |  5.95% |  400 |  5.30% |  400\n",
      "\t 25 | 00:18:03 ( 34) |  0.30 |   8 | 95% |  500 |  10.84% |  5.70% |  400 |  5.21% |  500\n",
      "\t 26 | 00:18:36 ( 33) |  0.30 |   8 | 30% |  500 |   8.25% |  5.92% |  350 |  5.32% |  450\n",
      "\t 27 | 00:19:10 ( 34) |  0.10 |   8 | 60% | 1000 |   8.17% |  6.07% |  500 |  5.65% |  450\n",
      "\t 28 | 00:19:50 ( 40) |  0.30 |  32 | 60% | 1000 |   8.17% |  4.65% |  100 |  4.25% |  350\n",
      "\t 29 | 00:20:38 ( 48) |  0.01 |  32 | 60% |  250 |   7.56% |  4.71% |  500 |  3.61% |  500\n",
      "\t 30 | 00:21:45 ( 67) |  0.01 | 128 | 60% |  250 |   8.05% |  5.54% |  500 |  4.95% |  500\n",
      "\t 31 | 00:22:15 ( 31) |  0.10 |   4 | 30% |  500 |   6.68% |  5.21% |  500 |  4.60% |  450\n",
      "\t 32 | 00:23:33 ( 78) |  0.10 | 128 | 95% |  250 |   9.03% |  5.62% |  100 |  5.11% |  150\n",
      "\t 33 | 00:24:36 ( 62) |  0.10 | 128 | 30% |  500 |   8.47% |  5.63% |  200 |  5.21% |  100\n",
      "\t 34 | 00:26:11 ( 95) |  0.01 | 128 | 95% |  250 |   8.49% |  5.84% |  500 |  5.12% |  500\n",
      "\t 35 | 00:27:15 ( 65) |  0.30 | 128 | 30% | 1000 |   7.11% |  4.80% |   10 |  4.70% |   10\n",
      "\t 36 | 00:27:52 ( 36) |  0.01 |   8 | 60% | 1000 |   5.95% |  3.95% |  500 |  2.99% |  450\n",
      "\t 37 | 00:28:50 ( 58) |  0.10 | 128 | 60% |  500 |   9.01% |  5.67% |  250 |  5.30% |  350\n",
      "\t 38 | 00:29:24 ( 34) |  0.01 |   8 | 30% | 1000 |   5.52% |  3.81% |  500 |  3.24% |  500\n",
      "\t 39 | 00:29:60 ( 36) |  0.01 |   8 | 60% |  500 |   5.71% |  3.96% |  500 |  2.90% |  500\n",
      "\t 40 | 00:30:38 ( 39) |  0.01 |   8 | 95% |  250 |   5.72% |  4.26% |  500 |  3.09% |  500\n",
      "\t 41 | 00:31:11 ( 32) |  0.01 |   4 | 95% |  500 |   5.46% |  4.93% |   25 |  5.22% |   25\n",
      "\t 42 | 00:31:42 ( 31) |  0.01 |   4 | 30% |  250 |   4.52% |  3.75% |  400 |  3.83% |  200\n",
      "\t 43 | 00:32:25 ( 44) |  0.01 |  32 | 30% |  500 |   5.42% |  4.85% |  500 |  4.21% |  500\n",
      "\t 44 | 00:32:57 ( 32) |  0.10 |   4 | 95% | 1000 |   7.34% |  4.68% |  450 |  4.19% |  400\n",
      "\t 45 | 00:34:45 (108) |  0.01 | 128 | 95% | 1000 |   8.15% |  5.82% |  500 |  5.25% |  500\n",
      "\t 46 | 00:35:17 ( 31) |  0.01 |   4 | 95% |  250 |   5.56% |  4.93% |   25 |  5.22% |   25\n",
      "\t 47 | 00:35:52 ( 36) |  0.01 |   8 | 60% |  250 |   5.55% |  3.96% |  500 |  3.24% |  250\n",
      "\t 48 | 00:37:17 ( 85) |  0.10 | 128 | 95% |  500 |   8.88% |  5.44% |  250 |  5.18% |  350\n",
      "\t 49 | 00:37:47 ( 30) |  0.30 |   4 | 60% |  250 |   9.32% |  5.92% |  350 |  5.23% |  400\n",
      "\t 50 | 00:38:21 ( 33) |  0.10 |   8 | 60% |  500 |   7.73% |  5.46% |  400 |  4.99% |  400\n",
      "\t 51 | 00:38:59 ( 38) |  0.30 |  32 | 60% |  250 |   9.33% |  5.37% |  150 |  4.57% |  150\n",
      "\t 52 | 00:39:40 ( 41) |  0.30 |  32 | 30% | 1000 |   7.86% |  4.97% |  200 |  4.55% |  200\n",
      "\t 53 | 00:40:10 ( 30) |  0.10 |   4 | 60% | 1000 |   6.84% |  5.12% |  500 |  4.57% |  500\n",
      "Lookahead: 21 | Train: 1134 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:00:33 ( 33) |  0.30 |   8 | 30% |  250 |   3.96% |  8.97% |  300 |  8.30% |  400\n",
      "\t  1 | 00:01:39 ( 66) |  0.10 | 128 | 30% | 1000 |   4.15% |  8.01% |  200 |  7.80% |  250\n",
      "\t  2 | 00:02:12 ( 33) |  0.01 |   4 | 60% | 1000 |   7.93% |  7.04% |  350 |  6.37% |   75\n",
      "\t  3 | 00:03:34 ( 83) |  0.30 | 128 | 95% |  500 |   5.21% |  7.31% |   25 |  6.12% |   25\n",
      "\t  4 | 00:04:13 ( 39) |  0.01 |   8 | 60% | 1000 |   5.89% |  7.12% |  500 |  5.71% |   10\n",
      "\t  5 | 00:04:45 ( 32) |  0.10 |   4 | 60% |  500 |   8.04% |  8.41% |  500 |  6.88% |  500\n",
      "\t  6 | 00:05:16 ( 31) |  0.30 |   4 | 30% |  250 |   5.62% |  8.73% |  450 |  7.37% |  500\n",
      "\t  7 | 00:05:53 ( 37) |  0.10 |   8 | 95% |  500 |   5.64% |  8.65% |  400 |  7.65% |  400\n",
      "\t  8 | 00:06:26 ( 33) |  0.10 |   4 | 95% |  250 |   7.59% |  8.32% |  350 |  7.75% |   10\n",
      "\t  9 | 00:07:02 ( 36) |  0.10 |   8 | 60% |  250 |   6.93% |  9.34% |  250 |  8.09% |  250\n",
      "\t 10 | 00:07:47 ( 45) |  0.01 |  32 | 30% | 1000 |   2.19% |  7.17% |  500 |  5.71% |  500\n",
      "\t 11 | 00:08:21 ( 34) |  0.10 |   8 | 30% |  250 |   2.84% |  8.78% |  350 |  7.84% |  350\n",
      "\t 12 | 00:09:20 ( 59) |  0.01 |  32 | 95% |  250 |   4.62% |  7.77% |  500 |  6.29% |  450\n",
      "\t 13 | 00:09:54 ( 33) |  0.30 |   8 | 60% |  250 |   6.35% |  9.69% |  100 |  8.49% |  100\n",
      "\t 14 | 00:10:26 ( 32) |  0.10 |   4 | 95% |  500 |   7.59% |  8.43% |  250 |  7.75% |   10\n",
      "\t 15 | 00:11:15 ( 49) |  0.10 |  32 | 60% | 1000 |   7.71% |  8.43% |  250 |  7.79% |  200\n",
      "\t 16 | 00:11:49 ( 35) |  0.01 |   4 | 95% |  250 |   7.86% |  9.79% |   75 |  10.92% |   75\n",
      "\t 17 | 00:12:34 ( 44) |  0.30 |  32 | 60% |  500 |   5.93% |  8.93% |   50 |  8.47% |  100\n",
      "\t 18 | 00:13:07 ( 34) |  0.30 |   4 | 95% |  250 |   7.79% |  7.67% |  450 |  6.84% |   10\n",
      "\t 19 | 00:13:42 ( 35) |  0.30 |   8 | 60% |  500 |   6.84% |  9.77% |  200 |  8.81% |  150\n",
      "\t 20 | 00:14:16 ( 34) |  0.01 |   4 | 95% |  500 |   7.95% |  9.85% |   75 |  10.95% |   75\n",
      "\t 21 | 00:15:26 ( 70) |  0.30 | 128 | 60% | 1000 |   4.29% |  6.23% |   25 |  5.39% |   25\n",
      "\t 22 | 00:16:56 ( 91) |  0.10 | 128 | 95% | 1000 |   5.08% |  7.69% |  150 |  6.97% |  150\n",
      "\t 23 | 00:17:37 ( 41) |  0.01 |   8 | 95% | 1000 |   6.51% |  7.94% |   25 |  8.36% |   25\n",
      "\t 24 | 00:18:10 ( 32) |  0.30 |   4 | 95% |  500 |   7.79% |  8.24% |  150 |  7.33% |  150\n",
      "\t 25 | 00:19:31 ( 81) |  0.10 | 128 | 95% |  500 |   5.30% |  8.01% |  200 |  7.53% |  200\n",
      "\t 26 | 00:20:09 ( 39) |  0.01 |   8 | 60% |  500 |   6.07% |  7.18% |  500 |  6.02% |   10\n",
      "\t 27 | 00:20:55 ( 46) |  0.10 |  32 | 60% |  500 |   6.68% |  8.83% |  300 |  8.08% |  200\n",
      "\t 28 | 00:21:34 ( 39) |  0.01 |   8 | 60% |  250 |   6.15% |  7.07% |  500 |  6.02% |   10\n",
      "\t 29 | 00:22:06 ( 31) |  0.30 |   4 | 30% | 1000 |   5.24% |  9.44% |  400 |  8.76% |  500\n",
      "\t 30 | 00:22:37 ( 32) |  0.10 |   4 | 30% |  500 |   5.57% |  8.76% |  500 |  7.31% |  500\n",
      "\t 31 | 00:23:13 ( 35) |  0.01 |   8 | 30% |  500 |   4.11% |  6.39% |  500 |  5.16% |   25\n",
      "\t 32 | 00:24:18 ( 65) |  0.30 | 128 | 30% | 1000 |   4.53% |  6.97% |   75 |  6.52% |   75\n",
      "\t 33 | 00:25:31 ( 73) |  0.10 | 128 | 60% |  500 |   7.08% |  7.05% |  250 |  6.06% |  500\n",
      "\t 34 | 00:26:28 ( 57) |  0.30 | 128 | 30% |  250 |   4.79% |  5.86% |   25 |  5.09% |   50\n",
      "\t 35 | 00:26:60 ( 32) |  0.01 |   4 | 30% | 1000 |   6.19% |  6.16% |  350 |  6.04% |   25\n",
      "\t 36 | 00:27:33 ( 33) |  0.10 |   4 | 60% | 1000 |   7.97% |  8.54% |  400 |  6.94% |  450\n",
      "\t 37 | 00:28:04 ( 32) |  0.10 |   4 | 30% |  250 |   5.85% |  8.34% |  500 |  7.29% |  500\n",
      "\t 38 | 00:28:36 ( 32) |  0.10 |   4 | 60% |  250 |   8.04% |  8.18% |  500 |  6.28% |  500\n",
      "\t 39 | 00:29:09 ( 33) |  0.30 |   4 | 95% | 1000 |   7.76% |  7.48% |  150 |  6.77% |  500\n",
      "\t 40 | 00:30:48 ( 99) |  0.01 | 128 | 95% |  500 |   4.08% |  8.35% |  500 |  6.81% |  500\n",
      "\t 41 | 00:31:30 ( 42) |  0.30 |  32 | 60% |  250 |   6.22% |  6.78% |   75 |  6.18% |  150\n",
      "\t 42 | 00:32:06 ( 36) |  0.10 |   8 | 60% |  500 |   6.56% |  8.64% |  350 |  7.80% |  500\n",
      "\t 43 | 00:32:51 ( 45) |  0.01 |  32 | 30% |  500 |   2.22% |  7.08% |  500 |  5.50% |  500\n",
      "\t 44 | 00:33:52 ( 61) |  0.01 |  32 | 95% | 1000 |   3.92% |  8.12% |  500 |  6.94% |  500\n",
      "\t 45 | 00:34:34 ( 42) |  0.10 |  32 | 30% |  500 |   4.41% |  8.61% |  350 |  7.86% |  300\n",
      "\t 46 | 00:35:40 ( 66) |  0.01 | 128 | 30% |  250 |   2.42% |  7.47% |  500 |  6.72% |  500\n",
      "\t 47 | 00:36:12 ( 32) |  0.01 |   4 | 30% |  500 |   6.30% |  6.26% |  350 |  6.12% |   25\n",
      "\t 48 | 00:36:44 ( 31) |  0.30 |   4 | 60% |  500 |   6.82% |  9.13% |  400 |  8.04% |  450\n",
      "\t 49 | 00:37:40 ( 56) |  0.01 |  32 | 60% | 1000 |   4.92% |  7.92% |  500 |  6.03% |  400\n",
      "\t 50 | 00:38:57 ( 77) |  0.10 | 128 | 95% |  250 |   5.75% |  8.49% |   75 |  8.05% |  100\n",
      "\t 51 | 00:39:29 ( 32) |  0.01 |   4 | 60% |  250 |   7.87% |  7.00% |   75 |  6.58% |   75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 52 | 00:40:03 ( 34) |  0.10 |   4 | 95% | 1000 |   7.85% |  8.19% |  450 |  7.75% |   10\n",
      "\t 53 | 00:40:37 ( 34) |  0.30 |   8 | 30% | 1000 |   3.59% |  7.91% |  300 |  7.72% |  450\n",
      "Lookahead:  5 | Train: 252 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:00:16 ( 16) |  0.10 |   8 | 60% | 1000 |   5.19% |  3.64% |  300 |  2.79% |   50\n",
      "\t  1 | 00:00:29 ( 13) |  0.30 |   4 | 30% | 1000 |   4.98% |  4.32% |   50 |  3.67% |   50\n",
      "\t  2 | 00:00:45 ( 15) |  0.30 |   8 | 60% | 1000 |   5.16% |  3.16% |  100 |  2.39% |  150\n",
      "\t  3 | 00:01:20 ( 35) |  0.30 | 128 | 30% |  250 |   4.48% |  2.55% |   50 |  2.13% |  200\n",
      "\t  4 | 00:01:43 ( 23) |  0.01 |  32 | 30% | 1000 |   4.53% |  4.17% |   75 |  3.77% |  100\n",
      "\t  5 | 00:01:59 ( 16) |  0.30 |   8 | 95% | 1000 |   5.35% |  3.96% |   50 |  2.74% |  100\n",
      "\t  6 | 00:02:21 ( 22) |  0.10 |  32 | 60% | 1000 |   5.28% |  3.42% |   75 |  2.64% |  450\n",
      "\t  7 | 00:02:53 ( 32) |  0.30 | 128 | 60% |  250 |   4.96% |  3.01% |   25 |  2.56% |  150\n",
      "\t  8 | 00:03:26 ( 33) |  0.01 | 128 | 60% | 1000 |   5.04% |  3.87% |   75 |  3.50% |   25\n",
      "\t  9 | 00:03:46 ( 20) |  0.30 |  32 | 60% |  250 |   5.03% |  2.98% |   75 |  2.27% |   50\n",
      "\t 10 | 00:04:27 ( 41) |  0.01 | 128 | 60% |  500 |   4.95% |  3.31% |   50 |  2.72% |   50\n",
      "\t 11 | 00:04:50 ( 23) |  0.30 |  32 | 95% |  250 |   5.37% |  3.17% |  350 |  2.64% |  350\n",
      "\t 12 | 00:05:07 ( 17) |  0.01 |   8 | 60% | 1000 |   4.52% |  3.53% |  500 |  3.02% |  500\n",
      "\t 13 | 00:05:24 ( 17) |  0.10 |   8 | 60% |  500 |   5.55% |  3.72% |  500 |  2.99% |  500\n",
      "\t 14 | 00:05:37 ( 14) |  0.01 |   4 | 30% | 1000 |   4.02% |  3.20% |  400 |  3.22% |  450\n",
      "\t 15 | 00:06:23 ( 46) |  0.10 | 128 | 95% | 1000 |   5.56% |  3.33% |   50 |  2.75% |  150\n",
      "\t 16 | 00:06:39 ( 15) |  0.10 |   8 | 30% |  250 |   4.84% |  3.94% |  200 |  3.46% |   50\n",
      "\t 17 | 00:07:07 ( 28) |  0.01 |  32 | 95% |  500 |   4.86% |  3.41% |  500 |  2.42% |  500\n",
      "\t 18 | 00:07:23 ( 16) |  0.10 |   8 | 30% | 1000 |   5.23% |  4.25% |  200 |  3.71% |   75\n",
      "\t 19 | 00:08:08 ( 45) |  0.01 | 128 | 95% |  250 |   5.47% |  3.53% |  500 |  2.60% |  150\n",
      "\t 20 | 00:08:22 ( 15) |  0.01 |   4 | 60% | 1000 |   4.26% |  3.32% |  400 |  3.41% |  400\n",
      "\t 21 | 00:08:41 ( 19) |  0.10 |   8 | 95% | 1000 |   5.32% |  3.64% |  400 |  3.12% |  400\n",
      "\t 22 | 00:08:56 ( 15) |  0.01 |   4 | 60% |  250 |   4.30% |  3.47% |  400 |  3.41% |  250\n",
      "\t 23 | 00:09:42 ( 46) |  0.10 | 128 | 30% |  500 |   4.67% |  3.58% |   25 |  2.87% |   25\n",
      "\t 24 | 00:10:26 ( 44) |  0.10 | 128 | 95% |  250 |   5.33% |  3.44% |   75 |  2.55% |  450\n",
      "\t 25 | 00:10:42 ( 16) |  0.30 |   4 | 95% |  500 |   5.75% |  3.93% |  150 |  3.10% |  150\n",
      "\t 26 | 00:11:08 ( 26) |  0.10 |  32 | 95% | 1000 |   5.43% |  3.48% |  200 |  2.84% |  200\n",
      "\t 27 | 00:11:32 ( 24) |  0.01 |  32 | 30% |  500 |   4.68% |  3.96% |  450 |  3.87% |  200\n",
      "\t 28 | 00:11:56 ( 24) |  0.01 |  32 | 60% |  250 |   4.99% |  3.60% |  500 |  2.78% |  150\n",
      "\t 29 | 00:12:10 ( 14) |  0.01 |   4 | 30% |  250 |   4.14% |  3.47% |  350 |  3.82% |  300\n",
      "\t 30 | 00:12:25 ( 15) |  0.10 |   4 | 60% |  500 |   4.98% |  3.70% |  500 |  3.20% |   50\n",
      "\t 31 | 00:13:11 ( 45) |  0.10 | 128 | 30% | 1000 |   4.98% |  4.08% |   25 |  3.47% |   25\n",
      "\t 32 | 00:13:26 ( 16) |  0.01 |   4 | 95% |  500 |   4.29% |  3.80% |  300 |  3.31% |  300\n",
      "\t 33 | 00:13:42 ( 16) |  0.30 |   4 | 95% |  250 |   5.23% |  3.83% |   10 |  3.03% |   50\n",
      "\t 34 | 00:13:59 ( 17) |  0.30 |   8 | 95% |  250 |   4.98% |  3.24% |  100 |  2.47% |  200\n",
      "\t 35 | 00:14:22 ( 23) |  0.10 |  32 | 30% |  500 |   4.93% |  4.16% |   25 |  3.45% |   25\n",
      "\t 36 | 00:14:36 ( 14) |  0.01 |   4 | 30% |  500 |   4.07% |  3.50% |  300 |  3.35% |  400\n",
      "\t 37 | 00:15:03 ( 27) |  0.01 |  32 | 95% | 1000 |   4.93% |  3.51% |  500 |  2.37% |   75\n",
      "\t 38 | 00:15:47 ( 44) |  0.30 | 128 | 30% | 1000 |   4.42% |  3.00% |   25 |  2.54% |  350\n",
      "\t 39 | 00:16:02 ( 15) |  0.10 |   4 | 60% |  250 |   4.81% |  3.75% |   25 |  3.62% |   50\n",
      "\t 40 | 00:16:18 ( 16) |  0.30 |   8 | 60% |  250 |   5.61% |  3.81% |   50 |  3.32% |   25\n",
      "\t 41 | 00:16:34 ( 16) |  0.01 |   4 | 95% |  250 |   4.35% |  3.64% |  300 |  3.39% |  300\n",
      "\t 42 | 00:16:48 ( 14) |  0.10 |   4 | 30% |  500 |   4.85% |  3.82% |  250 |  3.25% |  250\n",
      "\t 43 | 00:17:09 ( 21) |  0.30 |  32 | 30% |  250 |   4.89% |  3.66% |   25 |  3.06% |   25\n",
      "\t 44 | 00:17:25 ( 16) |  0.10 |   4 | 95% |  500 |   5.19% |  3.53% |  400 |  3.22% |   10\n",
      "\t 45 | 00:17:41 ( 16) |  0.01 |   8 | 30% |  250 |   4.62% |  3.39% |  400 |  3.23% |  150\n",
      "\t 46 | 00:17:56 ( 15) |  0.30 |   4 | 60% |  500 |   5.30% |  3.53% |  500 |  2.92% |  500\n",
      "\t 47 | 00:18:11 ( 15) |  0.30 |   4 | 60% | 1000 |   5.25% |  3.15% |  200 |  2.93% |  350\n",
      "\t 48 | 00:18:27 ( 16) |  0.10 |   8 | 30% |  500 |   4.88% |  4.08% |  200 |  3.56% |  200\n",
      "\t 49 | 00:18:46 ( 19) |  0.01 |   8 | 95% | 1000 |   4.55% |  3.40% |  300 |  2.94% |   75\n",
      "\t 50 | 00:19:02 ( 16) |  0.01 |   8 | 30% |  500 |   4.70% |  3.53% |  500 |  3.44% |   75\n",
      "\t 51 | 00:19:18 ( 16) |  0.10 |   4 | 95% |  250 |   5.12% |  3.69% |  400 |  3.32% |   10\n",
      "\t 52 | 00:20:04 ( 47) |  0.01 | 128 | 30% |  500 |   4.99% |  4.57% |  100 |  4.58% |  100\n",
      "\t 53 | 00:20:43 ( 38) |  0.10 | 128 | 60% |  250 |   5.51% |  3.33% |  150 |  2.54% |  150\n"
     ]
    }
   ],
   "source": [
    "for lookahead, train_length, test_length in test_params:\n",
    "    # randomized grid search\n",
    "    cvp = np.random.choice(list(range(n_params)),\n",
    "                           size=int(n_params / 2),\n",
    "                           replace=False)\n",
    "    cv_params_ = [cv_params[i] for i in cvp]\n",
    "\n",
    "    # set up cross-validation\n",
    "    n_splits = int(2 * YEAR / test_length)\n",
    "    print(f'Lookahead: {lookahead:2.0f} | '\n",
    "          f'Train: {train_length:3.0f} | '\n",
    "          f'Test: {test_length:2.0f} | '\n",
    "          f'Params: {len(cv_params_):3.0f} | '\n",
    "          f'Train configs: {len(test_params)}')\n",
    "\n",
    "    # time-series cross-validation\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              lookahead=lookahead,\n",
    "                              test_period_length=test_length,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    label = label_dict[lookahead]\n",
    "    outcome_data = data.loc[:, features + [label]].dropna()\n",
    "    \n",
    "    # binary dataset\n",
    "    lgb_data = lgb.Dataset(data=outcome_data.drop(label, axis=1),\n",
    "                           label=outcome_data[label],\n",
    "                           categorical_feature=categoricals,\n",
    "                           free_raw_data=False)\n",
    "    T = 0\n",
    "    predictions, metrics, feature_importance, daily_ic = [], [], [], []\n",
    "    \n",
    "    # iterate over (shuffled) hyperparameter combinations\n",
    "    for p, param_vals in enumerate(cv_params_):\n",
    "        key = f'{lookahead}/{train_length}/{test_length}/' + '/'.join([str(p) for p in param_vals])\n",
    "        params = dict(zip(param_names, param_vals))\n",
    "        params.update(base_params)\n",
    "\n",
    "        start = time()\n",
    "        cv_preds, nrounds = [], []\n",
    "        ic_cv = defaultdict(list)\n",
    "        \n",
    "        # iterate over folds\n",
    "        for i, (train_idx, test_idx) in enumerate(cv.split(X=outcome_data)):\n",
    "            \n",
    "            # select train subset\n",
    "            lgb_train = lgb_data.subset(used_indices=train_idx.tolist(),\n",
    "                                       params=params).construct()\n",
    "            \n",
    "            # train model for num_boost_round\n",
    "            model = lgb.train(params=params,\n",
    "                              train_set=lgb_train,\n",
    "                              num_boost_round=num_boost_round,\n",
    "                              verbose_eval=False)\n",
    "            # log feature importance\n",
    "            if i == 0:\n",
    "                fi = get_fi(model).to_frame()\n",
    "            else:\n",
    "                fi[i] = get_fi(model)\n",
    "\n",
    "            # capture predictions\n",
    "            test_set = outcome_data.iloc[test_idx, :]\n",
    "            X_test = test_set.loc[:, model.feature_name()]\n",
    "            y_test = test_set.loc[:, label]\n",
    "            y_pred = {str(n): model.predict(X_test, num_iteration=n) for n in num_iterations}\n",
    "            \n",
    "            # record predictions for each fold\n",
    "            cv_preds.append(y_test.to_frame('y_test').assign(**y_pred).assign(i=i))\n",
    "        \n",
    "        # combine fold results\n",
    "        cv_preds = pd.concat(cv_preds).assign(**params)\n",
    "        predictions.append(cv_preds)\n",
    "        \n",
    "        # compute IC per day\n",
    "        by_day = cv_preds.groupby(level='date')\n",
    "        ic_by_day = pd.concat([by_day.apply(lambda x: spearmanr(x.y_test, x[str(n)])[0]).to_frame(n)\n",
    "                               for n in num_iterations], axis=1)\n",
    "        daily_ic_mean = ic_by_day.mean()\n",
    "        daily_ic_mean_n = daily_ic_mean.idxmax()\n",
    "        daily_ic_median = ic_by_day.median()\n",
    "        daily_ic_median_n = daily_ic_median.idxmax()\n",
    "        \n",
    "        # compute IC across all predictions\n",
    "        ic = [spearmanr(cv_preds.y_test, cv_preds[str(n)])[0] for n in num_iterations]\n",
    "        t = time() - start\n",
    "        T += t\n",
    "        \n",
    "        # collect metrics\n",
    "        metrics = pd.Series(list(param_vals) +\n",
    "                            [t, daily_ic_mean.max(), daily_ic_mean_n, daily_ic_median.max(), daily_ic_median_n] + ic,\n",
    "                            index=metric_cols)\n",
    "        msg = f'\\t{p:3.0f} | {format_time(T)} ({t:3.0f}) | {params[\"learning_rate\"]:5.2f} | '\n",
    "        msg += f'{params[\"num_leaves\"]:3.0f} | {params[\"feature_fraction\"]:3.0%} | {params[\"min_data_in_leaf\"]:4.0f} | '\n",
    "        msg += f' {max(ic):6.2%} | {ic_by_day.mean().max(): 6.2%} | {daily_ic_mean_n: 4.0f} | {ic_by_day.median().max(): 6.2%} | {daily_ic_median_n: 4.0f}'\n",
    "        print(msg)\n",
    "\n",
    "        # persist results for given CV run and hyperparameter combination\n",
    "        metrics.to_hdf(lgb_store, 'metrics/' + key)\n",
    "        ic_by_day.assign(**params).to_hdf(lgb_store, 'daily_ic/' + key)\n",
    "        fi.T.describe().T.assign(**params).to_hdf(lgb_store, 'fi/' + key)\n",
    "        cv_preds.to_hdf(lgb_store, 'predictions/' + key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat a similar process for CatBoost - see book and CatBoost [docs](https://catboost.ai/docs/concepts/about.html) for detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.002366Z",
     "start_time": "2020-06-21T03:17:13.861Z"
    }
   },
   "outputs": [],
   "source": [
    "param_names = ['max_depth', 'min_child_samples']\n",
    "\n",
    "max_depth_opts = [3, 5, 7, 9]\n",
    "min_child_samples_opts = [20, 250, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.002915Z",
     "start_time": "2020-06-21T03:17:14.083Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_params = list(product(max_depth_opts,\n",
    "                         min_child_samples_opts))\n",
    "n_params = len(cv_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Period Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.003547Z",
     "start_time": "2020-06-21T03:17:14.456Z"
    }
   },
   "outputs": [],
   "source": [
    "lookaheads = [1, 5, 21]\n",
    "# lookaheads = [1, 5]\n",
    "label_dict = dict(zip(lookaheads, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.004201Z",
     "start_time": "2020-06-21T03:17:16.556Z"
    }
   },
   "outputs": [],
   "source": [
    "train_lengths = [int(4.5 * 252), 252]\n",
    "test_lengths = [63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.004875Z",
     "start_time": "2020-06-21T03:17:17.116Z"
    }
   },
   "outputs": [],
   "source": [
    "test_params = list(product(lookaheads,\n",
    "                           train_lengths,\n",
    "                           test_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.005692Z",
     "start_time": "2020-06-21T03:17:18.773Z"
    }
   },
   "outputs": [],
   "source": [
    "class CatBoostIC(object):\n",
    "    \"\"\"Custom IC eval metric for CatBoost\"\"\"\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        # Returns whether great values of metric are better\n",
    "        return True\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        target = np.array(target)\n",
    "        approxes = np.array(approxes).reshape(-1)\n",
    "        rho = spearmanr(approxes, target)[0]\n",
    "        return rho, 1\n",
    "\n",
    "    def get_final_error(self, error, weight):\n",
    "        # Returns final value of metric based on error and weight\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.006427Z",
     "start_time": "2020-06-21T03:17:29.495Z"
    }
   },
   "outputs": [],
   "source": [
    "cb_store = Path(results_path / 'tuning_catboost.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.007167Z",
     "start_time": "2020-06-21T03:17:29.677Z"
    }
   },
   "outputs": [],
   "source": [
    "num_iterations = [10, 25, 50, 75] + list(range(100, 1001, 100))\n",
    "num_boost_round = num_iterations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.007861Z",
     "start_time": "2020-06-21T03:17:29.812Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_cols = (param_names + ['t', 'daily_ic_mean', 'daily_ic_mean_n',\n",
    "                              'daily_ic_median', 'daily_ic_median_n'] +\n",
    "               [str(n) for n in num_iterations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.008624Z",
     "start_time": "2020-06-21T03:17:30.033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookahead:  1 | Train: 1134 | Test: 63 | Params:  12 | Train configs: 6\n",
      "  0 | 00:05:34 (334) |   9 |  250 |   0.30% | -0.03% |   25 |  0.06% |   25\n",
      "  1 | 00:10:19 (285) |   9 |   20 |   0.30% | -0.03% |   25 |  0.06% |   25\n",
      "  2 | 00:12:30 (131) |   3 |   20 |   0.55% | -0.17% |  100 |  0.21% |  100\n",
      "  3 | 00:16:13 (223) |   7 |  500 |  -1.00% | -0.19% |   10 |  0.07% |   10\n",
      "  4 | 00:19:15 (182) |   5 |  500 |  -0.49% | -0.16% |   10 |  0.04% |   10\n",
      "  5 | 00:21:25 (130) |   3 |  500 |   0.55% | -0.17% |  100 |  0.21% |  100\n",
      "  6 | 00:23:36 (131) |   3 |  250 |   0.55% | -0.17% |  100 |  0.21% |  100\n",
      "  7 | 00:28:20 (284) |   9 |  500 |   0.30% | -0.03% |   25 |  0.06% |   25\n",
      "  8 | 00:31:20 (180) |   5 |  250 |  -0.49% | -0.16% |   10 |  0.04% |   10\n",
      "  9 | 00:35:02 (222) |   7 |  250 |  -1.00% | -0.19% |   10 |  0.07% |   10\n",
      " 10 | 00:38:00 (178) |   5 |   20 |  -0.49% | -0.16% |   10 |  0.04% |   10\n",
      " 11 | 00:41:41 (221) |   7 |   20 |  -1.00% | -0.19% |   10 |  0.07% |   10\n",
      "Lookahead:  1 | Train: 252 | Test: 63 | Params:  12 | Train configs: 6\n",
      "  0 | 00:02:44 (164) |   9 |  250 |   0.22% | -0.44% |   10 |  0.24% |   10\n",
      "  1 | 00:05:29 (166) |   9 |   20 |   0.22% | -0.44% |   10 |  0.24% |   10\n",
      "  2 | 00:06:46 ( 76) |   3 |   20 |   0.47% | -0.03% |   10 |  0.19% |  200\n",
      "  3 | 00:08:49 (123) |   7 |  500 |   0.30% | -0.48% |   10 | -0.01% |   50\n",
      "  4 | 00:10:53 (124) |   7 |   20 |   0.30% | -0.48% |   10 | -0.01% |   50\n",
      "  5 | 00:12:29 ( 96) |   5 |   20 |   0.61% | -0.43% |   10 | -0.08% |   50\n",
      "  6 | 00:13:45 ( 77) |   3 |  250 |   0.47% | -0.03% |   10 |  0.19% |  200\n",
      "  7 | 00:15:22 ( 97) |   5 |  250 |   0.61% | -0.43% |   10 | -0.08% |   50\n",
      "  8 | 00:16:58 ( 96) |   5 |  500 |   0.61% | -0.43% |   10 | -0.08% |   50\n",
      "  9 | 00:18:13 ( 75) |   3 |  500 |   0.47% | -0.03% |   10 |  0.19% |  200\n",
      " 10 | 00:20:57 (164) |   9 |  500 |   0.22% | -0.44% |   10 |  0.24% |   10\n",
      " 11 | 00:23:03 (125) |   7 |  250 |   0.30% | -0.48% |   10 | -0.01% |   50\n",
      "Lookahead:  5 | Train: 1134 | Test: 63 | Params:  12 | Train configs: 6\n",
      "  0 | 00:03:43 (223) |   7 |  250 |   3.10% | -0.08% |   25 | -0.04% |   25\n"
     ]
    }
   ],
   "source": [
    "for lookahead, train_length, test_length in test_params:\n",
    "    cvp = np.random.choice(list(range(n_params)),\n",
    "                           size=int(n_params / 1),\n",
    "                           replace=False)\n",
    "    cv_params_ = [cv_params[i] for i in cvp]\n",
    "\n",
    "    n_splits = int(2 * YEAR / test_length)\n",
    "    print(f'Lookahead: {lookahead:2.0f} | Train: {train_length:3.0f} | '\n",
    "          f'Test: {test_length:2.0f} | Params: {len(cv_params_):3.0f} | Train configs: {len(test_params)}')\n",
    "\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              lookahead=lookahead,\n",
    "                              test_period_length=test_length,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    label = label_dict[lookahead]\n",
    "    outcome_data = data.loc[:, features + [label]].dropna()\n",
    "    cat_cols_idx = [outcome_data.columns.get_loc(c) for c in categoricals]\n",
    "    catboost_data = Pool(label=outcome_data[label],\n",
    "                         data=outcome_data.drop(label, axis=1),\n",
    "                         cat_features=cat_cols_idx)\n",
    "    predictions, metrics, feature_importance, daily_ic = [], [], [], []\n",
    "    key = f'{lookahead}/{train_length}/{test_length}'\n",
    "    T = 0\n",
    "    for p, param_vals in enumerate(cv_params_):\n",
    "        params = dict(zip(param_names, param_vals))\n",
    "        # uncomment if running with GPU\n",
    "        params['task_type'] = 'GPU'\n",
    "\n",
    "        start = time()\n",
    "        cv_preds, nrounds = [], []\n",
    "        ic_cv = defaultdict(list)\n",
    "        for i, (train_idx, test_idx) in enumerate(cv.split(X=outcome_data)):\n",
    "            train_set = catboost_data.slice(train_idx.tolist())\n",
    "\n",
    "            model = CatBoostRegressor(**params)\n",
    "            model.fit(X=train_set,\n",
    "                      verbose_eval=False)\n",
    "\n",
    "            test_set = outcome_data.iloc[test_idx, :]\n",
    "            X_test = test_set.loc[:, model.feature_names_]\n",
    "            y_test = test_set.loc[:, label]\n",
    "            y_pred = {str(n): model.predict(X_test, ntree_end=n)\n",
    "                      for n in num_iterations}\n",
    "            cv_preds.append(y_test.to_frame(\n",
    "                'y_test').assign(**y_pred).assign(i=i))\n",
    "\n",
    "        cv_preds = pd.concat(cv_preds).assign(**params)\n",
    "        predictions.append(cv_preds)\n",
    "        by_day = cv_preds.groupby(level='date')\n",
    "        ic_by_day = pd.concat([by_day.apply(lambda x: spearmanr(x.y_test, x[str(n)])[0]).to_frame(n)\n",
    "                               for n in num_iterations], axis=1)\n",
    "        daily_ic_mean = ic_by_day.mean()\n",
    "        daily_ic_mean_n = daily_ic_mean.idxmax()\n",
    "        daily_ic_median = ic_by_day.median()\n",
    "        daily_ic_median_n = daily_ic_median.idxmax()\n",
    "\n",
    "        ic = [spearmanr(cv_preds.y_test, cv_preds[str(n)])[0]\n",
    "              for n in num_iterations]\n",
    "        t = time() - start\n",
    "        T += t\n",
    "        metrics = pd.Series(list(param_vals) +\n",
    "                            [t, daily_ic_mean.max(), daily_ic_mean_n,\n",
    "                             daily_ic_median.max(), daily_ic_median_n] + ic,\n",
    "                            index=metric_cols)\n",
    "        msg = f'{p:3.0f} | {format_time(T)} ({t:3.0f}) | {params[\"max_depth\"]:3.0f} | {params[\"min_child_samples\"]:4.0f} | '\n",
    "        msg += f' {max(ic):6.2%} | {ic_by_day.mean().max(): 6.2%} | {daily_ic_mean_n: 4.0f} | {ic_by_day.median().max(): 6.2%} | {daily_ic_median_n: 4.0f}'\n",
    "        print(msg)\n",
    "        metrics.to_hdf(cb_store, 'metrics/' + key)\n",
    "        ic_by_day.assign(**params).to_hdf(cb_store, 'daily_ic/' + key)\n",
    "        cv_preds.to_hdf(cb_store, 'predictions/' + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml4t_orginal]",
   "language": "python",
   "name": "conda-env-ml4t_orginal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.031px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
